{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "R = [('Adele',8),('Bob',22),('Clement',16),('Dave',23),('Ed',11),\n",
    "     ('Fung',25),('Goel',3),('Harry',17),('Irene',14),('Joanna',2),\n",
    "     ('Kelly',6),('Lim',20),('Meng',1),('Noor',5),('Omar',19)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "S = [('Arts',8),('Business',15),('CompSc',2),('Dance',12),\n",
    "     ('Engineering',7 ), ('Finance',21),('Geology',10),\n",
    "     ('Health',11),('IT',18)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Serial Join Algorithms\n",
    "## 1.1 Nested-loop join\n",
    "\n",
    "Perform the _**nested-loop**_ join algorithms.  \n",
    "It consists of two levels of loops: \n",
    "* inner loop (looping for the second table) \n",
    "* outer loop (looping for the ﬁrst table).\n",
    "\n",
    "**If there are _N_ records in table T1 and _M_ records in table T2**.  \n",
    "### Time Complexity: \n",
    "* _**O**( N * M )_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NL_join(T1, T2):\n",
    "    result = []\n",
    "    for tr1 in T1:\n",
    "        for tr2 in T2:\n",
    "            if tr1[1] == tr2[1]:\n",
    "                result.append({\", \".join([tr1[0],str(tr1[1]),\n",
    "                                          tr2[0]])})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Adele, 8, Arts'}, {'Ed, 11, Health'}, {'Joanna, 2, CompSc'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NL_join(R,S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 2 Sort-merge join\n",
    "\n",
    "**Sort-Merge join** is based on sorting and merging operations  \n",
    "basically just do the sorting before merging two tables.\n",
    "\n",
    "### Time Complexity:\n",
    " * **Sorting**: _**O**( N logN )_ and _**O**( M logM )_\n",
    " * **Merging**: _**O**( N + M )_ _(which is linear)_ \n",
    "\n",
    "Better than Nested-loop join ( _**O**( N * M )_ )  \n",
    "Especially if N and M are **very large**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0', 23], ['1', 6], ['2', 9], ['3', 15], ['4', 27], ['5', 20], ['6', 13], ['7', 14], ['8', 11], ['9', 8]]\n",
      "[['1', 6], ['9', 8], ['2', 9], ['8', 11], ['6', 13], ['7', 14], ['3', 15], ['5', 20], ['0', 23], ['4', 27]]\n"
     ]
    }
   ],
   "source": [
    "from random import *\n",
    "pattern = [str(x) for x in range(10)]\n",
    "a = [randrange(30) for x in range(10)]\n",
    "sample = []\n",
    "for p, a in zip(pattern, a):\n",
    "    sample.append([p,a])\n",
    "print(sample)\n",
    "result = sorted(sample, key = lambda each:each[1])\n",
    "# Sorted function: \n",
    "# Arguments list:\n",
    "# 1. iterable object\n",
    "# 2. key = a function to customize the sort order\n",
    "# 3. reverse flag = True for descending order.(By default is False)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Joanna', 2, 'CompSc'], ['Adele', 8, 'Arts'], ['Ed', 11, 'Health']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def SM_join(T1, T2):\n",
    "    result = []\n",
    "    # convert to list of lists\n",
    "    s_T1 = list(T1)\n",
    "    # sort T1 based on the join attribute    \n",
    "    s_T1 = sorted(s_T1, key=lambda each: each[1])\n",
    "    s_T2 = list(T2) \n",
    "    s_T2 = sorted(s_T2, key=lambda each: each[1])\n",
    "    i = 0\n",
    "    j = 0\n",
    "    while i < len(T1) and j < len(T2):\n",
    "        r = s_T1[i][1] \n",
    "        s = s_T2[j][1]\n",
    "        if r == s:\n",
    "            result.append([s_T1[i][0], r, s_T2[j][0]])\n",
    "            i+=1\n",
    "            j+=1\n",
    "        elif r < s:\n",
    "            i += 1\n",
    "        else:\n",
    "            j += 1\n",
    "    return result\n",
    "\n",
    "SM_join(R, S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Hash_Based join\n",
    "Made up of two processes: **Hasing** and **Probing**  \n",
    "* **Hashing**: hash all records of the ﬁrst table using a hash function   \n",
    "* **Probing**: \n",
    "   * Hash Again: hash all records of the second table record by record.\n",
    "   * Search & Match: if hashing to a nonempty index entry then examine each record in that entry.\n",
    "   \n",
    "### Time Complexity:\n",
    "_**O**( N + M )_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def H(r):\n",
    "    digits = [int(d) for d in str(r[1])]\n",
    "    #convert input into string then back to integer\n",
    "    return sum(digits) #Sum up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def HB_join(T1,T2):\n",
    "    result = []\n",
    "    dic = {}\n",
    "    for s in T2:\n",
    "        # First, do hashing to the smaller table\n",
    "        s_key = H(s)\n",
    "        # Group elements with the same hash value\n",
    "        if s_key in dic:\n",
    "            dic[s_key].add(s)\n",
    "        else:\n",
    "            dic[s_key] = {s}\n",
    "            # The reason of using set data type is to handle \n",
    "            # collison problem\n",
    "            # (multiple data with the same hash table index)\n",
    "    #Then to probe\n",
    "    for r in T1:\n",
    "        r_key = H(r)\n",
    "        if r_key in dic:\n",
    "            # using 'in' will directly check on the dict's keys\n",
    "            # Then, load dataset with the same hash value\n",
    "            dataset = dic[r_key]\n",
    "            for data in dataset:\n",
    "                if data[1] == r[1]:\n",
    "                    result.append({\", \".join([r[0],str(r[1]),\n",
    "                                             data[0]])})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Adele, 8, Arts'}, {'Ed, 11, Health'}, {'Joanna, 2, CompSc'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HB_join(R,S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison:\n",
    "The complexity of join algorithms is normally dependent on the number of times that a **disk scan** (_**the most expensive operation**_) needs to be performed.  \n",
    "> **Minimizing disk scan** is the ultimate objective not only in join algorithms, but also in any query processing algorithms.\n",
    "\n",
    "* **Nested-loop join** algorithm:\n",
    "> _**O(** N \\* M **)**_ **  \n",
    "> ==>** Exponential\n",
    "* **Sort-merge join** algorithm:\n",
    "> _**O(** N logN + M logM + N + M **)**_  \n",
    "> **==>** better than exponential but not good as linear\n",
    "* **Hash-based join** algorithm:  \n",
    "> _**O(** N + M **)**_  \n",
    "> **==>** Linear (The **Most Efficient** join algorithm)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Parallel Join Algorithms\n",
    "### * The join operation is one of the most expensive operations in relational query processing, and hence the parallelizing join operation brings significant benefits.\n",
    "## 2.1 Divide and Broadcast-based Parallel Join \n",
    "Composed of TWO stages:\n",
    "* Data partitioning by using **_Divide and broadcast method_**\n",
    "* **_Local join_**\n",
    "\n",
    "> About **Divide and broadcast**\\*:  \n",
    "> \\> **Divide**: Dividing one table by using equal division ( _**Round-robin**_ )  \n",
    "> \\> **Broadcasting**: actual is **replicating** the content of the second table to all processors.  \n",
    "> \\* _the **smaller** to be broadcast, the **larger** to be divided_.  \n",
    "> \\* **REPLICATION ONLY** in shared-nothing architecture, **NO REPLICATION** in shared-memory architecture.\n",
    "\n",
    "\n",
    "### **The divide and broadcast-based** parallel join algorithm\n",
    "> Based on **_nested-loop join_**  \n",
    ">     ==> also called **Parallel nested-loop join algorithm**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For shared-memory architecture:\n",
    "### The hash partitioning-based parallel join algorithm\n",
    "> Based on **_hash join_**  \n",
    ">     ==> also called **Parallel hash join algorithm**  \n",
    "> \\* hash partition + local join(Hash join is fast)\n",
    "\n",
    "### The range partitioning-based parallel join algorithm\n",
    "> Based on **_sort-merge join_**  \n",
    ">     ==> also called **Sort-merge join algorithm**  \n",
    "> \\* sorting + division + local join(Hash join is fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Adele', 8), ('Dave', 23), ('Goel', 3), ('Joanna', 2), ('Meng', 1)],\n",
       " [('Bob', 22), ('Ed', 11), ('Harry', 17), ('Kelly', 6), ('Noor', 5)],\n",
       " [('Clement', 16), ('Fung', 25), ('Irene', 14), ('Lim', 20), ('Omar', 19)]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Round-robin partitioning (equal division)\n",
    "def rr_partition(data, n):\n",
    "    result = []\n",
    "    for i in range(n):\n",
    "        result.append([])\n",
    "    n_bin = len(data)/n\n",
    "    for index, element in enumerate(data):\n",
    "        index_bin = (int)(index % n)\n",
    "        #print(\":\".join([str(index_bin),str(element)]))#For checking\n",
    "        result[index_bin].append(element)\n",
    "    return result\n",
    "\n",
    "rr_partition(R, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "# import Python multiprocessing module\n",
    "# \n",
    "def DPP_join(T1, T2, n_processor):\n",
    "    result = []\n",
    "    T1_subsets = rr_partition(T1, n_processor)\n",
    "    # T1 is equally divided by using Round-Robin partitioning\n",
    "    pool = mp.Pool(processes = n_processor)\n",
    "    # Pool instance\n",
    "    for t1 in T1_subsets:\n",
    "        # inner loop for each processor\n",
    "        result.append(pool.apply(HB_join,[t1,T2]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'Adele, 8, Arts'}, {'Joanna, 2, CompSc'}], [{'Ed, 11, Health'}], []]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DPP_join(R,S,3)\n",
    "# Each list is a result yield by one processor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2.2 Disjoint Partitioning-based Parallel Join\n",
    "Composed of TWO stages:\n",
    "* Data partitioning by using **_Disjoint partitioning_**\n",
    "* **_Local join_**\n",
    "> ABOUT Disjoint partitioning:  \n",
    "> such as **range partitioning** or **hash partitioning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def range_partition_v2(data, range_indices):\n",
    "    result = []\n",
    "    sorted_data = sorted(data, key=lambda each:each[1])\n",
    "    n_bin = len(range_indices)\n",
    "    for i in range(n_bin):\n",
    "        s = [x for x in sorted_data if x[1] < range_indices[i]]\n",
    "        result.append(s)\n",
    "        sorted_data = sorted_data[len(s):]\n",
    "    result.append([x for x in sorted_data if x[1] >= range_indices[-1]])\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Meng', 1),\n",
       "  ('Joanna', 2),\n",
       "  ('Goel', 3),\n",
       "  ('Noor', 5),\n",
       "  ('Kelly', 6),\n",
       "  ('Adele', 8)],\n",
       " [('Ed', 11), ('Irene', 14), ('Clement', 16), ('Harry', 17), ('Omar', 19)],\n",
       " [('Lim', 20), ('Bob', 22), ('Dave', 23), ('Fung', 25)]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range_partition_v2(R,[10,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DPBP_join(T1, T2, n_processor,local_join = HB_join):\n",
    "    result = []\n",
    "    # Pre-sorted\n",
    "    sorted_T1 = sorted(T1, key=lambda each:each[1])\n",
    "    sorted_T2 = sorted(T2, key=lambda each:each[1])\n",
    "    '''\n",
    "    each_range = sorted_T1[-1][1]//n_processor\n",
    "    range_indices = [each_range, 2*each_range]\n",
    "    print(range_indices) # For check\n",
    "    '''\n",
    "    range_indices = [10,20]\n",
    "    # Both T1 and T2 are partitioned\n",
    "    new_T1 = range_partition_v2(T1, range_indices)\n",
    "    new_T2 = range_partition_v2(T2, range_indices)\n",
    "    pool = mp.Pool(processes = n_processor)\n",
    "    for t1,t2 in zip(new_T1, new_T2):\n",
    "        result.append(pool.apply(local_join,[t1,t2]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'Joanna, 2, CompSc'}, {'Adele, 8, Arts'}], [{'Ed, 11, Health'}], []]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DPBP_join(R,S,3,NL_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Joanna', 2, 'CompSc'], ['Adele', 8, 'Arts']], [['Ed', 11, 'Health']], []]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DPBP_join(R,S,3,SM_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'Joanna, 2, CompSc'}, {'Adele, 8, Arts'}], [{'Ed, 11, Health'}], []]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DPBP_join(R,S,3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
