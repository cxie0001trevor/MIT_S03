{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nD = []\\ndef case_generator(n):\\n    for i in range(0,n):\\n        if i <100:\\n            D.append(randint(1,100))\\n        else:\\n            break\\ncase_generator(30)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "D = []\n",
    "def case_generator(n):\n",
    "    for i in range(0,n):\n",
    "        if i <100:\n",
    "            D.append(randint(1,100))\n",
    "        else:\n",
    "            break\n",
    "case_generator(30)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Partitioning\n",
    "## 1.1 Round-Robin Partioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import *\n",
    "D = [55,30,68,39,1,\n",
    "     4,49,90,34,76, \n",
    "     82,56,31,25,78, \n",
    "     56,38,32,88,9, \n",
    "     44,98,11,70,66, \n",
    "     89,99,22,23,26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[55, 39, 49, 76, 31, 56, 88, 98, 66, 22],\n",
       " [30, 1, 90, 82, 25, 38, 9, 11, 89, 23],\n",
       " [68, 4, 34, 56, 78, 32, 44, 70, 99, 26]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rr_partition(data, n):\n",
    "    '''\n",
    "Round-robin data partition:\n",
    "the simplest data partitioning method;\n",
    "each record in turn is allocated to a processing element (simply processor);\n",
    "Distributes the data evenly among all processors;\n",
    "Known as “equal-partitioning”.\n",
    "    '''\n",
    "    result = []\n",
    "    #Creating partition n as list of lists\n",
    "    for i in range(n):\n",
    "        result.append([])\n",
    "    #enumerate data and evenly allocation to according partition\n",
    "    for index, element in enumerate(data):\n",
    "        index_bin = (int)(index % n) \n",
    "        #Trick: e.g. 1%4=1; 2%4=2; 3%4=3; 4%4=0\n",
    "        result[index_bin].append(element)\n",
    "    return result\n",
    "\n",
    "rr_partition(D,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Hash Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[55, 30, 68, 39, 1, 4, 49, 90, 34, 76, 82, 56, 31, 25, 78, 56, 38, 32, 88, 9, 44, 98, 11, 70, 66, 89, 99, 22, 23, 26]\n",
      "{1, 34, 4, 70, 76, 49, 82, 22, 55, 88, 25, 31}\n",
      "{66, 99, 39, 9, 78, 90, 30}\n",
      "{32, 98, 68, 38, 11, 44, 23, 56, 89, 26}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Hash data partition:\n",
    "    Partitioning based on a particular attribute using \n",
    "    a hash function. all records within a partition have\n",
    "    the same hash value.\n",
    "'''\n",
    "def hash_func(x, n):\n",
    "    return x%n\n",
    "\n",
    "def h_partition(data, n):\n",
    "    dic = {} #Using hash value as the key of the item\n",
    "    for element in data:\n",
    "        h_value = hash_func(element, n)\n",
    "        if (h_value in dic.keys()):\n",
    "            items = dic[h_value]\n",
    "            items.add(element) \n",
    "            # Mark: using Set\n",
    "            dic[h_value] = items\n",
    "        else:\n",
    "            '''\n",
    "            Note: using Set can avoid duplicated data.\n",
    "            Searching data in a dict with hash value is O(1).\n",
    "            Without duplicated record, to some extent, the\n",
    "            efficiency can be improved.\n",
    "            '''\n",
    "            tmp = set()\n",
    "            tmp.update({element})\n",
    "            dic[h_value] = tmp\n",
    "    return dic\n",
    "print(D)\n",
    "results = h_partition(D, 3)\n",
    "for each in results:\n",
    "    print(results[each])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[55, 30, 68, 39, 1, 4, 49, 90, 34, 76, 82, 56, 31, 25, 78, 56, 38, 32, 88, 9, 44, 98, 11, 70, 66, 89, 99, 22, 23, 26]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: [30, 39, 90, 78, 9, 66, 99],\n",
       " 1: [55, 1, 4, 49, 34, 76, 82, 31, 25, 88, 70, 22],\n",
       " 2: [68, 56, 56, 38, 32, 44, 98, 11, 89, 23, 26]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def h_partition_listVersion(data, n):\n",
    "    dic = {} #Using hash value as the key of the item\n",
    "    for element in data:\n",
    "        h_value = hash_func(element, n)\n",
    "        if (h_value in dic.keys()):\n",
    "            items = dic[h_value]\n",
    "            items.append(element) \n",
    "            # Mark: List Question\n",
    "            dic[h_value] = items\n",
    "        else:\n",
    "            '''\n",
    "            Note: Just curious why not using List\n",
    "            '''\n",
    "            tmp = []\n",
    "            tmp.append(element)\n",
    "            dic[h_value] = tmp\n",
    "    return dic\n",
    "print(D)\n",
    "h_partition_listVersion(D, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Range Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def range_partition(data, range_indices):\n",
    "    result = []\n",
    "    sorted_data = sorted(data)#replicate data\n",
    "    n_bin = len(range_indices)\n",
    "    for i in range(n_bin):\n",
    "        s = [x for x in sorted_data if x < range_indices[i]]\n",
    "        '''\n",
    "        Separate data by the range:\n",
    "        e.g, let a range to be [40,60], a list contain range(100)\n",
    "        this comprehensive list slice the [0, 40), [40,60)\n",
    "        '''\n",
    "        result.append(s)\n",
    "        sorted_data = sorted_data[len(s):]\n",
    "        '''\n",
    "        Qestion solved:\n",
    "        Error occur when data contain duplicated record\n",
    "        which accidentally rest at the edge of the range\n",
    "        #Original code:\n",
    "        #last_index = sorted_data.index(s[-1])\n",
    "        #sorted_data = sorted_data[last_index+1:]\n",
    "        ''' \n",
    "    result.append([x for x in sorted_data if x >= range_indices[-1]])\n",
    "    '''\n",
    "    The last line finish the slicing.[60,100]\n",
    "    '''\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 4, 9, 11, 22, 23, 25, 26, 30, 31, 32, 34, 38, 39],\n",
       " [44, 49, 55, 56, 56, 66, 68],\n",
       " [70, 76, 78, 82, 88, 89, 90, 98, 99]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range_partition(D,[40,70])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Random-Unequal Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ru_partition(data, n):\n",
    "    '''\n",
    "    Perform random-unequal data partitioning on data\n",
    "    Arguments:\n",
    "    data -- an input dataset which is a list \n",
    "    n -- the number of processors\n",
    "    Return:\n",
    "    result -- the paritioned subsets of D\n",
    "    '''\n",
    "    result = []\n",
    "    for i in range(n):\n",
    "        result.append([])\n",
    "    #enumerate data and evenly allocation to according partition\n",
    "    for element in data:\n",
    "        # partition rules:\n",
    "        index_bin = int(sum([int(d) for d in str(element)]) % n)\n",
    "        result[index_bin].append(element)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ru_partition_setVersion(data, n):\n",
    "    '''\n",
    "    Perform random-unequal data partitioning on data\n",
    "    Arguments:\n",
    "    data -- an input dataset which is a list \n",
    "    n -- the number of processors\n",
    "    Return:\n",
    "    result -- the paritioned subsets of D\n",
    "    '''\n",
    "    result = {}\n",
    "    #enumerate data and evenly allocation to according partition\n",
    "    for element in data:\n",
    "        # partition rules:\n",
    "        index_bin = int(sum([int(d) for d in str(element)]) % n)\n",
    "        if index_bin in result.keys():\n",
    "            result[index_bin].add(element)\n",
    "        else:\n",
    "            result[index_bin] = {element}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[55, 39, 49, 76, 31, 56, 88, 98, 66, 22],\n",
       " [30, 1, 90, 82, 25, 38, 9, 11, 89, 23],\n",
       " [68, 4, 34, 56, 78, 32, 44, 70, 99, 26]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr_partition(D,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[30, 39, 90, 78, 9, 66, 99],\n",
       " [55, 1, 4, 49, 34, 76, 82, 31, 25, 88, 70, 22],\n",
       " [68, 56, 56, 38, 32, 44, 98, 11, 89, 23, 26]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_partition(D,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {9, 30, 39, 66, 78, 90, 99},\n",
       " 1: {1, 4, 22, 25, 31, 34, 49, 55, 70, 76, 82, 88},\n",
       " 2: {11, 23, 26, 32, 38, 44, 56, 68, 89, 98}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_partition_setVersion(D,3)\n",
    "# Note: \n",
    "# 1. No duplicate data in set\n",
    "# 2. Data in set followed the ascending order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Search Algorithms\n",
    "## 2.1 Linear Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_search(data, key):\n",
    "    '''\n",
    "    Linear Search(Exhaustive search)\n",
    "    Arguments:\n",
    "    data -- an input dataset which is a list or a numpy array \n",
    "    key -- an query record\n",
    "    Return:\n",
    "    result -- the position of searched record\n",
    "    '''\n",
    "    matched_record = 'Not Found' \n",
    "    position = -1 # not found position\n",
    "    ### START CODE HERE ### \n",
    "    for x in data:\n",
    "        if x == key: # If x is matched with key\n",
    "            matched_record = x \n",
    "            position = data.index(x) # Get the index of x \n",
    "            break\n",
    "    ### END CODE HERE ###\n",
    "    return (position, matched_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = [1,2,4,2,5,1]\n",
    "linear_search(D, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Binary Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarySearch(alist, record):\n",
    "    \"\"\" \n",
    "    Perform binary search on data for the given key\n",
    "    Arguments:\n",
    "    alist -- an input dataset which is a list \n",
    "    record -- an query record\n",
    "    Return:\n",
    "    result -- the position of searched record\n",
    "    \"\"\"\n",
    "    if alist:\n",
    "        print(alist)\n",
    "        data = sorted(alist)\n",
    "        while len(data)!=1:\n",
    "            mid = len(data)//2\n",
    "            if data[mid] == record:\n",
    "                return alist.index(record), record\n",
    "            elif data[mid] < record:\n",
    "                #go right, slice off the left-side\n",
    "                data = data[mid:]\n",
    "            else:\n",
    "                #go left, slice off the right-side\n",
    "                data = data[:mid]\n",
    "        if data[0] != record:\n",
    "            return -1,'Not Found'\n",
    "        else:\n",
    "            return alist.index(record),record\n",
    "    else:\n",
    "        print(\"Input Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 4, 2, 5, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-1, 'Not Found')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binarySearch(D,31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Parallel Search Algorithms\n",
    "## 3.1 Parallel Searching for Exact Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_search_exact(data, query, n_processor, m_partition, m_search):\n",
    "    \"\"\"\n",
    "    Perform parallel search for exact match on data for the given key\n",
    "    Arguments:\n",
    "    data -- an input dataset which is a list \n",
    "    query -- a query record \n",
    "    n_processor -- the number of parallel processors \n",
    "    m_partition -- a data partitioning method \n",
    "    m_search -- a search method\n",
    "    Return:\n",
    "    results -- the matched record information\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    # Pool: a Python method enabling parallel processing.\n",
    "    # We need to set the number of processes to n_processor,\n",
    "    # which means that the Pool class will only allow 'n_processor' processes \n",
    "    # running at the same time.\n",
    "    pool = Pool(processes = n_processor)\n",
    "    ### START CODE HERE ###\n",
    "    print(\"data partitioning:\" + str(m_partition.__name__)) \n",
    "    print(\"searching method:\" + str(m_search.__name__))\n",
    "    print(\"Query: \" + str(query))\n",
    "    if m_partition == range_partition: \n",
    "        # for range partitioning method \n",
    "        # Perform data partitioning:\n",
    "        # 2nd parameter is a list of maximum range values (3 ranges) \n",
    "        DD = m_partition(data, [40, 80]) \n",
    "        for d in DD: # Find the range that may contain the query\n",
    "            if query in d:\n",
    "                print(\"Found corresponding range:\")\n",
    "                print(d)\n",
    "                m = list(d) \n",
    "                result = pool.apply(m_search, [m, query]) \n",
    "                results.append(result) \n",
    "                break\n",
    "    elif m_partition == h_partition: \n",
    "        # for hash partitioning method \n",
    "        # Perform data partitioning first \n",
    "        DD = m_partition(data, n_processor)\n",
    "        print(DD)\n",
    "        # Each element in DD has a pair (hash key: records) \n",
    "        query_hash = hash_func(query, n_processor) \n",
    "        print(\"Query Hash value: \" + str(query_hash))\n",
    "        d = list(DD[query_hash]) \n",
    "        print(\"Found corresponding partition:\")\n",
    "        print(d)\n",
    "        result = pool.apply(m_search, [d, query]) \n",
    "        results.append(result)\n",
    "    else: # for round-robin or random-unequal partitioning method \n",
    "        # Perform data partitioning first\n",
    "        DD = m_partition(data, n_processor) \n",
    "        for d in DD: # Perform parallel search on all data partitions\n",
    "            result = pool.apply(m_search, [d, query])\n",
    "            #output = result.get() # if you use pool.apply_sync(), uncomment this. \n",
    "            #results.append(output) # if you use pool.apply_sync(), uncomment this. \n",
    "            results.append(result) # if you use pool.apply_sync(), comment out this.\n",
    "\n",
    "        \"\"\" \n",
    "        The method above 'pool.apply()' will lock the function \n",
    "        program until all a process is finished. Alternatively,\n",
    "        we can use the 'pool.apply_sync()' method to spawn one \n",
    "        process for each CPU core on your machine.\n",
    "        \"\"\" \n",
    "    ### END CODE HERE ### \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sorted(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data partitioning:rr_partition\n",
      "searching method:linear_search\n",
      "Query: 31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(-1, 'Not Found'), (-1, 'Not Found'), (-1, 'Not Found')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# round-robin partition, linear_search\n",
    "parallel_search_exact(data, 31, 3, rr_partition, linear_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n",
      "[1, 4]\n",
      "[2, 5]\n",
      "data partitioning:rr_partition\n",
      "searching method:binarySearch\n",
      "Query: 31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(-1, 'Not Found'), (-1, 'Not Found'), (-1, 'Not Found')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# round-robin partition, binary_search\n",
    "parallel_search_exact(data, 31, 3, rr_partition, binarySearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data partitioning:ru_partition\n",
      "searching method:linear_search\n",
      "Query: 31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(-1, 'Not Found'), (-1, 'Not Found'), (-1, 'Not Found')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random-unequal partition, linear_search\n",
    "parallel_search_exact(data, 31, 3, ru_partition, linear_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Error\n",
      "[1, 1, 4]\n",
      "[2, 2, 5]\n",
      "data partitioning:ru_partition\n",
      "searching method:binarySearch\n",
      "Query: 31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, (-1, 'Not Found'), (-1, 'Not Found')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random-unequal partition, binary_search \n",
    "parallel_search_exact(data, 31, 3, ru_partition, binarySearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data partitioning:h_partition\n",
      "searching method:linear_search\n",
      "Query: 31\n",
      "{1: {1, 4}, 2: {2, 5}}\n",
      "Query Hash value: 1\n",
      "Found corresponding partition:\n",
      "[1, 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(-1, 'Not Found')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hash partition, linear_search \n",
    "parallel_search_exact(data, 31, 3, h_partition, linear_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data partitioning:h_partition\n",
      "searching method:binarySearch\n",
      "Query: 31\n",
      "{1: {1, 4}, 2: {2, 5}}\n",
      "Query Hash value: 1\n",
      "Found corresponding partition:\n",
      "[1, 4]\n",
      "[1, 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(-1, 'Not Found')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hash partition, binary_search \n",
    "parallel_search_exact(data, 31, 3, h_partition, binarySearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data partitioning:range_partition\n",
      "searching method:linear_search\n",
      "Query: 31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Range partition, linear_search \n",
    "parallel_search_exact(data, 31, 3, range_partition,linear_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data partitioning:range_partition\n",
      "searching method:binarySearch\n",
      "Query: 31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Range partition, binary_search\n",
    "parallel_search_exact(data, 31, 3, range_partition,binarySearch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Parallel Searching for Range Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Build a parallel search algorithm that uses the linear search\n",
    "algorithm (i.e. linear_search()) and is able to work with the\n",
    "hash partitioning method (i.e. h_partition()).\n",
    "'''\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-703691b6ea16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparallel_search_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-703691b6ea16>\u001b[0m in \u001b[0;36mparallel_search_range\u001b[0;34m(data, query_range, n_processor)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_processor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcandid_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear_search\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                     print(\"Found \" + str(result[1]) \n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "def parallel_search_range(data, query_range, n_processor):\n",
    "    results = []\n",
    "    pool = Pool(processes = n_processor)\n",
    "    DD = h_partition(data, n_processor)\n",
    "    if query_range[0] > query_range[1]:\n",
    "        raise Exception(\"Input Error\")\n",
    "    else:\n",
    "        candid_list = [x for x in range(query_range[0],query_range[1]+1)]\n",
    "        for i in range(n_processor):\n",
    "            for query in candid_list:\n",
    "                result = pool.apply(linear_search, [list(DD[i]), query])\n",
    "                if result[0] != -1:\n",
    "                    print(\"Found \" + str(result[1]) \n",
    "                          + \"from hash: \" + str(i))\n",
    "                    results.append(result)\n",
    "    return results\n",
    "\n",
    "results = parallel_search_range(data, [30, 40], 3) \n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
