{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 8 Part A\n",
    "\n",
    "There are four ways to merge/combine between different DataFrames in pandas: concatenating, appending, merging and joining. Each has its own use cases and best practice. We discussed in Tutorial 5 the both methods of Concatenating and appending. In this tutorial, we discuss both merge and join. \n",
    "\n",
    "## Methods for integrating data with Pandas:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "## 3. Merge:\n",
    "\n",
    "Concat and append have limited capabilities in joining tables through keys and considering the inter-relationship between tables. Merge and join on the other hand combine DataFrames based on a key. According to concepts of relational databases like SQL, there are three types of relationships between tables:\n",
    "\n",
    "1.\t**One-to-one:** When each primary key value relates to only one (or no) record in the related table.\n",
    "\n",
    "2.\t**One-to-many:** When the primary key table contains only one record that relates to none, one, or many records in the related table.\n",
    "\n",
    "3.\t**Many-to-many:** When each record in both tables can relate to any number of records (or no records) in the other table.\n",
    "\n",
    "We will discuss in the following how merge manages the three types of relationships. The following is an example of using merge for one-to-many relationship between table respresnts customer details and shopping history for each customer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Customer_ID First_Name Last_Name\n",
      "0           1         A1        B1\n",
      "1           2         A2        B2\n",
      "2           3         A3        B3\n",
      "3           4         A4        B4\n",
      "  Customer_ID Product_ID product\n",
      "0           1        100     Oil\n",
      "1           1        200   Sugar\n",
      "2           1        300     Tea\n",
      "3           4        400    Milk\n",
      "4           5        500    Eggs\n",
      "  Customer_ID First_Name Last_Name Product_ID product\n",
      "0           1         A1        B1        100     Oil\n",
      "1           1         A1        B1        200   Sugar\n",
      "2           1         A1        B1        300     Tea\n",
      "3           4         A4        B4        400    Milk\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "customers= pd.DataFrame({'Customer_ID': ['1', '2', '3', '4'],\n",
    "                      'First_Name': ['A1','A2','A3','A4'],\n",
    "                    'Last_Name': ['B1', 'B2', 'B3', 'B4']})\n",
    "shopping_history= pd.DataFrame({'Customer_ID': ['1', '1', '1', '4','5'],\n",
    "                            'Product_ID':['100','200','300','400','500'],\n",
    "                      'product': ['Oil','Sugar','Tea','Milk','Eggs']})\n",
    "merged_df= pd.merge(customers,shopping_history)\n",
    "print(customers)\n",
    "print(shopping_history)\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to change Customer_ID to another name!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Product_ID'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2524\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2525\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2526\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Product_ID'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d471ae9cc574>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmerged_df\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustomers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshopping_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Product_ID\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmerged_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     55\u001b[0m                          \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                          \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                          validate=validate)\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    563\u001b[0m         (self.left_join_keys,\n\u001b[1;32m    564\u001b[0m          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m          self.join_names) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    835\u001b[0m                         \u001b[0mright_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 837\u001b[0;31m                         \u001b[0mleft_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    838\u001b[0m                         \u001b[0mjoin_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2137\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2138\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2144\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2146\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1840\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1842\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1843\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1844\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3842\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3843\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3844\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3845\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2525\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2526\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2527\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2529\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Product_ID'"
     ]
    }
   ],
   "source": [
    "merged_df= pd.merge(customers,shopping_history, on=\"Product_ID\")\n",
    "print (merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note that if the key is not specified, merge uses the overlapping column names as the keys. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to merge:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When there are no common columns between the DataFrames, you need to specify the key to merge on. Use on, left_on and right_on attributes to define the key in DataFrames. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CID First_Name Last_Name\n",
      "0   1         A1        B1\n",
      "1   2         A2        B2\n",
      "2   3         A3        B3\n",
      "3   4         A4        B4\n",
      "  Customer_ID Product_ID product\n",
      "0           1        100     Oil\n",
      "1           1        200   Sugar\n",
      "2           1        300     Tea\n",
      "3           4        400    Milk\n",
      "4           5        500    Eggs\n",
      "  CID First_Name Last_Name Customer_ID Product_ID product\n",
      "0   1         A1        B1           1        100     Oil\n",
      "1   1         A1        B1           1        200   Sugar\n",
      "2   1         A1        B1           1        300     Tea\n",
      "3   4         A4        B4           4        400    Milk\n"
     ]
    }
   ],
   "source": [
    "customers2= pd.DataFrame({'CID': ['1', '2', '3', '4'],\n",
    "                      'First_Name': ['A1','A2','A3','A4'],\n",
    "                    'Last_Name': ['B1', 'B2', 'B3', 'B4']})\n",
    "merged_onkey= pd.merge(customers2,shopping_history,left_on='CID',right_on='Customer_ID')\n",
    "print (customers2) \n",
    "print (shopping_history)\n",
    "print (merged_onkey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The default \"how\" setting for merge is 'inner'!\n",
    "\n",
    "\n",
    "In the joined table, some records are deleted because they do not have a corresponding record in the original DataFrame (such as customer 2,3,5 and Eggs). This happens because the deafult method for merging is the inner join. For zero information loss, you can use outer join instead. The outer join could be full outer (getting full information from both DataFrames), left (only from the left DataFrame) or right (using left, right methods). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Customer_ID First_Name Last_Name\n",
      "0           1         A1        B1\n",
      "1           2         A2        B2\n",
      "2           3         A3        B3\n",
      "3           4         A4        B4\n",
      "  Customer_ID Product_ID product\n",
      "0           1        100     Oil\n",
      "1           1        200   Sugar\n",
      "2           1        300     Tea\n",
      "3           4        400    Milk\n",
      "4           5        500    Eggs\n",
      "  Customer_ID First_Name Last_Name Product_ID product\n",
      "0           1         A1        B1        100     Oil\n",
      "1           1         A1        B1        200   Sugar\n",
      "2           1         A1        B1        300     Tea\n",
      "3           2         A2        B2        NaN     NaN\n",
      "4           3         A3        B3        NaN     NaN\n",
      "5           4         A4        B4        400    Milk\n",
      "6           5        NaN       NaN        500    Eggs\n",
      "  Customer_ID First_Name Last_Name Product_ID product\n",
      "0           1         A1        B1        100     Oil\n",
      "1           1         A1        B1        200   Sugar\n",
      "2           1         A1        B1        300     Tea\n",
      "3           2         A2        B2        NaN     NaN\n",
      "4           3         A3        B3        NaN     NaN\n",
      "5           4         A4        B4        400    Milk\n",
      "  Customer_ID Product_ID product First_Name Last_Name\n",
      "0           1        100     Oil         A1        B1\n",
      "1           1        200   Sugar         A1        B1\n",
      "2           1        300     Tea         A1        B1\n",
      "3           4        400    Milk         A4        B4\n",
      "4           2        NaN     NaN         A2        B2\n",
      "5           3        NaN     NaN         A3        B3\n"
     ]
    }
   ],
   "source": [
    "print (customers)\n",
    "print (shopping_history)\n",
    "merged_outer= pd.merge(customers,shopping_history, how='outer')\n",
    "print (merged_outer)\n",
    "merged_left= pd.merge(customers,shopping_history, how='left')\n",
    "print (merged_left)\n",
    "merged_right= pd.merge(shopping_history,customers, how='right')\n",
    "print (merged_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Many-to-many merge:\n",
    "A more complicated relationship to manage using merge method is the many-to-many. Consider the example of customers and products. The customer DataFrame contains information about customers, while products has details about differnt grocery items. One customer can buy non or many products, and any product can be purchased by non or many customers. Pandas manage this relationship using merge method. Like SQL's JOIN clause, pandas.merge allows two DataFrames to be joined on one or more keys. The function provides a series of parameters (on, left_on, right_on, left_index, right_index) allowing you to specify the columns or indexes on which to join. In version 0.17.0. Pandas added the argument indicator. If True, a Categorical-type column called _merge will be added to the output object that takes on values. Here is a simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   d1 key\n",
      "0   0   a\n",
      "1   1   a\n",
      "2   2   b\n",
      "3   3   c\n",
      "4   4   a\n",
      "5   5   b\n",
      "6   6   c\n",
      "   d1 key\n",
      "0   0   d\n",
      "1   1   d\n",
      "2   2   b\n",
      "3   3   b\n",
      "4   4   b\n",
      "5   5   a\n",
      "    d1 key        True\n",
      "0    0   a   left_only\n",
      "1    1   a   left_only\n",
      "2    2   b        both\n",
      "3    3   c   left_only\n",
      "4    4   a   left_only\n",
      "5    5   b   left_only\n",
      "6    6   c   left_only\n",
      "7    0   d  right_only\n",
      "8    1   d  right_only\n",
      "9    3   b  right_only\n",
      "10   4   b  right_only\n",
      "11   5   a  right_only\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame({'key': ['a', 'a', 'b', 'c', 'a', 'b','c'], 'd1': range(7)})\n",
    "df2 = pd.DataFrame({'key': ['d', 'd', 'b', 'b', 'b', 'a'], 'd1': range(6)})\n",
    "print (df1)\n",
    "print (df2)\n",
    "merge= pd.merge(df1,df2, how='outer',indicator='True')\n",
    "print (merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   d1 key\n",
      "0   0   a\n",
      "1   1   a\n",
      "2   2   b\n",
      "3   3   c\n",
      "4   4   a\n",
      "5   5   b\n",
      "6   6   c\n",
      "   d1 key\n",
      "0   0   d\n",
      "1   1   d\n",
      "2   2   b\n",
      "3   3   b\n",
      "4   4   b\n",
      "5   5   a\n",
      "   d1 key_x key_y       True\n",
      "0   0     a     d       both\n",
      "1   1     a     d       both\n",
      "2   2     b     b       both\n",
      "3   3     c     b       both\n",
      "4   4     a     b       both\n",
      "5   5     b     a       both\n",
      "6   6     c   NaN  left_only\n"
     ]
    }
   ],
   "source": [
    "print (df1)\n",
    "print (df2)\n",
    "merge= pd.merge(df1,df2, how='outer',indicator='True', on='d1')\n",
    "print (merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In cases that there is a meaningful index in one of the columns, this index can replace the original DataFrame index. By default, set index returns a new DataFrame, so you will have to specify if you would like the changes to occur in place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Join:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            First_Name Last_Name\n",
      "Customer_ID                     \n",
      "1                   A1        B1\n",
      "2                   A2        B2\n",
      "3                   A3        B3\n",
      "4                   A4        B4\n",
      "            Product_ID product\n",
      "Customer_ID                   \n",
      "1                  100     Oil\n",
      "1                  200   Sugar\n",
      "1                  300     Tea\n",
      "4                  400    Milk\n",
      "5                  500    Eggs\n"
     ]
    }
   ],
   "source": [
    "customers.set_index('Customer_ID', inplace=True)\n",
    "shopping_history.set_index('Customer_ID', inplace=True)\n",
    "print (customers)\n",
    "print (shopping_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DataFrame also has a convenient join method for merging on the index. This is used when you have objects with similar row labels, but different columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            First_Name Last_Name\n",
      "Customer_ID                     \n",
      "1                   A1        B1\n",
      "2                   A2        B2\n",
      "3                   A3        B3\n",
      "4                   A4        B4\n",
      "            Product_ID product\n",
      "Customer_ID                   \n",
      "1                  100     Oil\n",
      "1                  200   Sugar\n",
      "1                  300     Tea\n",
      "4                  400    Milk\n",
      "5                  500    Eggs\n",
      "            First_Name Last_Name Product_ID product\n",
      "Customer_ID                                        \n",
      "1                   A1        B1        100     Oil\n",
      "1                   A1        B1        200   Sugar\n",
      "1                   A1        B1        300     Tea\n",
      "2                   A2        B2        NaN     NaN\n",
      "3                   A3        B3        NaN     NaN\n",
      "4                   A4        B4        400    Milk\n",
      "5                  NaN       NaN        500    Eggs\n"
     ]
    }
   ],
   "source": [
    "joined= customers.join(shopping_history,how=\"outer\")\n",
    "print (customers)\n",
    "print (shopping_history)\n",
    "print (joined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * Combining data with overlap: \n",
    "\n",
    "We use this method when we want to “patch” values in one object from values for matching indices in the other.  Note that this method only takes values from the right DataFrame if they are missing in the left DataFrame. Consider the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0   1    2\n",
      "0  1.0   3  NaN\n",
      "1  NaN  10  NaN\n",
      "2  NaN   5  3.0\n",
      "      0    1    2\n",
      "0  10.0  NaN  4.0\n",
      "1   NaN  5.0  3.0\n",
      "2   2.0  4.0  NaN\n",
      "     0   1    2\n",
      "0  1.0   3  4.0\n",
      "1  NaN  10  3.0\n",
      "2  2.0   5  3.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data1= pd.DataFrame([[1,3,np.nan],[np.nan,10,np.nan],[np.nan,5,3]])\n",
    "data2= pd.DataFrame([[10,np.nan,4],[np.nan,5,3],[2,4,np.nan]])\n",
    "print (data1)\n",
    "print (data2)\n",
    "data= data1.combine_first(data2)\n",
    "print (data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic data Reshaping: \n",
    "\n",
    "### Hierarchical indexing : Stack and unstack \n",
    "\n",
    "Hierarchical indexing provides a more structure way of presenting tabular data. There are two main methods for pivoting data with Hierarchical indexing. \n",
    "\n",
    "* stack: this “rotates” or pivots from the columns in the data to the rows\n",
    "* unstack: this pivots from the rows into the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     A         B\n",
      "first second                    \n",
      "L1_A  L2_1   -0.333475  0.932205\n",
      "      L2_2   -1.597954 -0.868185\n",
      "L1_B  L2_1   -0.062049 -0.290766\n",
      "      L2_2    0.870657 -1.317447\n",
      "L1_C  L2_1   -0.305033 -0.013570\n",
      "      L2_2   -0.030204  0.862827\n",
      "L1_D  L2_1   -1.353210 -0.481456\n",
      "      L2_2   -0.537739 -1.441681\n",
      "first  second   \n",
      "L1_A   L2_1    A   -0.333475\n",
      "               B    0.932205\n",
      "       L2_2    A   -1.597954\n",
      "               B   -0.868185\n",
      "L1_B   L2_1    A   -0.062049\n",
      "               B   -0.290766\n",
      "       L2_2    A    0.870657\n",
      "               B   -1.317447\n",
      "L1_C   L2_1    A   -0.305033\n",
      "               B   -0.013570\n",
      "       L2_2    A   -0.030204\n",
      "               B    0.862827\n",
      "L1_D   L2_1    A   -1.353210\n",
      "               B   -0.481456\n",
      "       L2_2    A   -0.537739\n",
      "               B   -1.441681\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "tuples = list(zip(*[['L1_A', 'L1_A', 'L1_B', 'L1_B','L1_C', 'L1_C', 'L1_D', 'L1_D'], ['L2_1', 'L2_2', 'L2_1','L2_2','L2_1', 'L2_2', 'L2_1','L2_2']]))\n",
    "index = pd.MultiIndex.from_tuples(tuples, names=['first', 'second'])\n",
    "data = pd.DataFrame(np.random.randn(8, 2), index=index, columns=['A', 'B'])\n",
    "print (data)\n",
    "result=data.stack()\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">A</th>\n",
       "      <th colspan=\"2\" halign=\"left\">B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second</th>\n",
       "      <th>L2_1</th>\n",
       "      <th>L2_2</th>\n",
       "      <th>L2_1</th>\n",
       "      <th>L2_2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>L1_A</th>\n",
       "      <td>-0.333475</td>\n",
       "      <td>-1.597954</td>\n",
       "      <td>0.932205</td>\n",
       "      <td>-0.868185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L1_B</th>\n",
       "      <td>-0.062049</td>\n",
       "      <td>0.870657</td>\n",
       "      <td>-0.290766</td>\n",
       "      <td>-1.317447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L1_C</th>\n",
       "      <td>-0.305033</td>\n",
       "      <td>-0.030204</td>\n",
       "      <td>-0.013570</td>\n",
       "      <td>0.862827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L1_D</th>\n",
       "      <td>-1.353210</td>\n",
       "      <td>-0.537739</td>\n",
       "      <td>-0.481456</td>\n",
       "      <td>-1.441681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               A                   B          \n",
       "second      L2_1      L2_2      L2_1      L2_2\n",
       "first                                         \n",
       "L1_A   -0.333475 -1.597954  0.932205 -0.868185\n",
       "L1_B   -0.062049  0.870657 -0.290766 -1.317447\n",
       "L1_C   -0.305033 -0.030204 -0.013570  0.862827\n",
       "L1_D   -1.353210 -0.537739 -0.481456 -1.441681"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Product_ID product\n",
      "Customer_ID                   \n",
      "1                  100     Oil\n",
      "1                  200   Sugar\n",
      "1                  300     Tea\n",
      "4                  400    Milk\n",
      "5                  500    Eggs\n",
      "            First_Name Last_Name\n",
      "Customer_ID                     \n",
      "1                   A1        B1\n",
      "2                   A2        B2\n",
      "3                   A3        B3\n",
      "4                   A4        B4\n",
      "            First_Name Last_Name Product_ID product\n",
      "Customer_ID                                        \n",
      "1                   A1        B1        100     Oil\n",
      "1                   A1        B1        200   Sugar\n",
      "1                   A1        B1        300     Tea\n",
      "2                   A2        B2        NaN     NaN\n",
      "3                   A3        B3        NaN     NaN\n",
      "4                   A4        B4        400    Milk\n",
      "5                  NaN       NaN        500    Eggs\n"
     ]
    }
   ],
   "source": [
    "joined= customers.join(shopping_history, how= 'outer')\n",
    "print (shopping_history)\n",
    "print (customers)\n",
    "print (joined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Try to implement the same code using pivot (http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.pivot.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplication: \n",
    "\n",
    "The DataFrame method 'duplicated' returns a Boolean Series indicating whether each row is a duplicate or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first  second\n",
       "L1_A   L2_1      False\n",
       "       L2_2      False\n",
       "L1_B   L2_1      False\n",
       "       L2_2      False\n",
       "L1_C   L2_1      False\n",
       "       L2_2      False\n",
       "L1_D   L2_1      False\n",
       "       L2_2      False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relatedly, 'drop_duplicates' returns a DataFrame where the duplicated array is without duplicated rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       k1  k2\n",
      "0    Milk   1\n",
      "1    Milk   1\n",
      "2    Milk   2\n",
      "3  Cheese   3\n",
      "4  Cheese   3\n",
      "5  Cheese   4\n",
      "6  Cheese   4\n",
      "       k1  k2\n",
      "0    Milk   1\n",
      "2    Milk   2\n",
      "3  Cheese   3\n",
      "5  Cheese   4\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame({'k1': ['Milk'] * 3 + ['Cheese'] * 4,  'k2': [1, 1, 2, 3, 3, 4, 4]})\n",
    "print (data)\n",
    "data.duplicated()\n",
    "cleandata= data.drop_duplicates()\n",
    "print (cleandata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may have noticed, applying drop_duplicates on the whole DataFrame considrs all othe columns together. We can alternatively specify which column we want to capture the duplication at. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       k1  k2\n",
      "0    Milk   1\n",
      "3  Cheese   3\n",
      "       k1  k2\n",
      "0    Milk   1\n",
      "2    Milk   2\n",
      "3  Cheese   3\n",
      "5  Cheese   4\n"
     ]
    }
   ],
   "source": [
    "v1= data.drop_duplicates(['k1'])\n",
    "print (v1)\n",
    "v2=  data.drop_duplicates(['k2'])\n",
    "print (v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming axis indexes: \n",
    "\n",
    "Pandas enable modifying the current attribute name using map or renaming methods. Example is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          day1  day2  day3  day4\n",
      "nsw          0     1     2     3\n",
      "vic          4     5     6     7\n",
      "tasmania     8     9    10    11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAY1</th>\n",
       "      <th>DAY2</th>\n",
       "      <th>DAY3</th>\n",
       "      <th>DAY4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NSW</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VIC</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TASMANIA</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DAY1  DAY2  DAY3  DAY4\n",
       "NSW          0     1     2     3\n",
       "VIC          4     5     6     7\n",
       "TASMANIA     8     9    10    11"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf= pd.DataFrame(np.arange(12).reshape((3, 4)), \n",
    "                  index=['nsw', 'vic', 'tasmania'],\n",
    "                  columns=['day1', 'day2', 'day3', 'day4'])\n",
    "print (idf)\n",
    "idf.index.map(str.upper)\n",
    "idf.rename(index=str.upper, columns=str.upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day1</th>\n",
       "      <th>day2</th>\n",
       "      <th>day3</th>\n",
       "      <th>day4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nsw</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vic</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tasmania</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          day1  day2  day3  day4\n",
       "nsw          0     1     2     3\n",
       "vic          4     5     6     7\n",
       "tasmania     8     9    10    11"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note rename keeps the original value of the data unchanged. To change the original DataFrame, you need to do that in place. You can also  rename a subset of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAY1</th>\n",
       "      <th>DAY2</th>\n",
       "      <th>DAY3</th>\n",
       "      <th>DAY4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NSW</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VIC</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TASMANIA</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DAY1  DAY2  DAY3  DAY4\n",
       "NSW          0     1     2     3\n",
       "VIC          4     5     6     7\n",
       "TASMANIA     8     9    10    11"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#idf.index=idf.index.map(str.upper)\n",
    "#OR\n",
    "idf.rename(index=str.upper, columns=str.upper, inplace=True)\n",
    "idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More details and examples can be found in http://pandas.pydata.org/pandas-docs/stable/merging.html and \"Python for Data Analysis\" book pages 177-193.\n",
    "https://nikolaygrozev.wordpress.com/2015/07/01/reshaping-in-pandas-pivot-pivot-table-stack-and-unstack-explained-with-pictures/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "name": "Chapter 6_Merging and Reshaping Data.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
