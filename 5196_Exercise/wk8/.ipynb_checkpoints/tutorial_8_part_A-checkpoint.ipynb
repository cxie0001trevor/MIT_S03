{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 8 Part A\n",
    "\n",
    "There are four ways to merge/combine between different DataFrames in pandas: <font color='blue'>**concatenating, appending, merging and joining**</font>. Each has its own use cases and best practice. We discussed in Tutorial 5 the both methods of Concatenating and appending. In this tutorial, we discuss both merge and join. \n",
    "\n",
    "## Methods for integrating data with Pandas:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "## 3. Merge:\n",
    "\n",
    "<font color='blue'>**Concat and append**</font> have limited capabilities in joining tables through keys and considering the inter-relationship between tables. <font color='blue'>**Merge and join**</font> on the other hand **combine DataFrames based on a key**. According to concepts of relational databases like SQL, there are three types of relationships between tables:\n",
    "\n",
    "1.\t**One-to-one:** When each primary key value relates to only one (or no) record in the related table.\n",
    "\n",
    "2.\t**One-to-many:** When the primary key table contains only one record that relates to none, one, or many records in the related table.\n",
    "\n",
    "3.\t**Many-to-many:** When each record in both tables can relate to any number of records (or no records) in the other table.\n",
    "\n",
    "We will discuss in the following how merge manages the three types of relationships. The following is an example of using merge for one-to-many relationship between table respresnts customer details and shopping history for each customer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One to Many Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Customer_ID First_Name Last_Name\n",
      "0           1         A1        B1\n",
      "1           2         A2        B2\n",
      "2           3         A3        B3\n",
      "3           4         A4        B4\n",
      "  Customer_ID Product_ID product\n",
      "0           1        100     Oil\n",
      "1           1        200   Sugar\n",
      "2           1        300     Tea\n",
      "3           4        400    Milk\n",
      "4           5        500    Eggs\n",
      "  Customer_ID First_Name Last_Name Product_ID product\n",
      "0           1         A1        B1        100     Oil\n",
      "1           1         A1        B1        200   Sugar\n",
      "2           1         A1        B1        300     Tea\n",
      "3           4         A4        B4        400    Milk\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "customers= pd.DataFrame({'Customer_ID': ['1', '2', '3', '4'],\n",
    "                      'First_Name': ['A1','A2','A3','A4'],\n",
    "                    'Last_Name': ['B1', 'B2', 'B3', 'B4']})\n",
    "shopping_history= pd.DataFrame({'Customer_ID': ['1', '1', '1', '4','5'],\n",
    "                            'Product_ID':['100','200','300','400','500'],\n",
    "                      'product': ['Oil','Sugar','Tea','Milk','Eggs']})\n",
    "merged_df= pd.merge(customers,shopping_history)\n",
    "print(customers)\n",
    "print(shopping_history)\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to change Customer_ID to another name!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Customer_ID First_Name Last_Name Product_ID product\n",
      "0           1         A1        B1        100     Oil\n",
      "1           1         A1        B1        200   Sugar\n",
      "2           1         A1        B1        300     Tea\n",
      "3           4         A4        B4        400    Milk\n"
     ]
    }
   ],
   "source": [
    "#customers.columns = ['Product_ID', 'First_Name', 'Last_Name']\n",
    "merged_df= pd.merge(customers,shopping_history)\n",
    "print (merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note that if the key is not specified, merge uses the overlapping column names as the keys. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Pandas documentation: Merge, join, and concatenate](https://pandas.pydata.org/pandas-docs/stable/merging.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to merge:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When there are **no common columns** between the DataFrames, you need to **specify the key to merge on**. Use **on**, **left_on** and **right_on** attributes to define the key in DataFrames. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CID First_Name Last_Name\n",
      "0   1         A1        B1\n",
      "1   2         A2        B2\n",
      "2   3         A3        B3\n",
      "3   4         A4        B4\n",
      "  Customer_ID Product_ID product\n",
      "0           1        100     Oil\n",
      "1           1        200   Sugar\n",
      "2           1        300     Tea\n",
      "3           4        400    Milk\n",
      "4           5        500    Eggs\n",
      "  CID First_Name Last_Name Customer_ID Product_ID product\n",
      "0   1         A1        B1           1        100     Oil\n",
      "1   1         A1        B1           1        200   Sugar\n",
      "2   1         A1        B1           1        300     Tea\n",
      "3   4         A4        B4           4        400    Milk\n"
     ]
    }
   ],
   "source": [
    "customers2= pd.DataFrame({'CID': ['1', '2', '3', '4'],\n",
    "                          'First_Name': ['A1','A2','A3','A4'],\n",
    "                          'Last_Name': ['B1', 'B2', 'B3', 'B4']})\n",
    "merged_onkey= pd.merge(customers2,shopping_history,left_on='CID',right_on='Customer_ID')\n",
    "print (customers2) \n",
    "print (shopping_history)\n",
    "print (merged_onkey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The default \"how\" setting for merge is 'inner'!\n",
    "\n",
    "\n",
    "In the joined table, some records are deleted because they do not have a corresponding record in the original DataFrame (such as customer 2,3,5 and Eggs). This happens because the deafult method for merging is the inner join. For zero information loss, you can use outer join instead. The outer join could be full outer (getting full information from both DataFrames), left (only from the left DataFrame) or right (using left, right methods). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##customers##\n",
      "  Customer_ID First_Name Last_Name\n",
      "0           1         A1        B1\n",
      "1           2         A2        B2\n",
      "2           3         A3        B3\n",
      "3           4         A4        B4\n",
      "------------------------------------------------\n",
      "##shopping_history##\n",
      "  Customer_ID Product_ID product\n",
      "0           1        100     Oil\n",
      "1           1        200   Sugar\n",
      "2           1        300     Tea\n",
      "3           4        400    Milk\n",
      "4           5        500    Eggs\n",
      "------------------------------------------------\n",
      "##Outer-Merge: 'customers' outer-merge on 'shopping_history'.##\n",
      "  Customer_ID First_Name Last_Name Product_ID product\n",
      "0           1         A1        B1        100     Oil\n",
      "1           1         A1        B1        200   Sugar\n",
      "2           1         A1        B1        300     Tea\n",
      "3           2         A2        B2        NaN     NaN\n",
      "4           3         A3        B3        NaN     NaN\n",
      "5           4         A4        B4        400    Milk\n",
      "6           5        NaN       NaN        500    Eggs\n",
      "#Customer ID as 5 in 'shopping_history' doesn't have record in 'customer'.\n",
      "------------------------------------------------\n",
      "##Left-Merge: 'customers' left-merge on 'shopping_history'.##\n",
      "  Customer_ID First_Name Last_Name Product_ID product\n",
      "0           1         A1        B1        100     Oil\n",
      "1           1         A1        B1        200   Sugar\n",
      "2           1         A1        B1        300     Tea\n",
      "3           2         A2        B2        NaN     NaN\n",
      "4           3         A3        B3        NaN     NaN\n",
      "5           4         A4        B4        400    Milk\n",
      "#Only Customer ID in 'customer' and their matching data in 'shopping_history'.\n",
      "------------------------------------------------\n",
      "##Right-Merge: 'shopping_history' right-merge on 'customers'.##\n",
      "  Customer_ID Product_ID product First_Name Last_Name\n",
      "0           1        100     Oil         A1        B1\n",
      "1           1        200   Sugar         A1        B1\n",
      "2           1        300     Tea         A1        B1\n",
      "3           4        400    Milk         A4        B4\n",
      "4           2        NaN     NaN         A2        B2\n",
      "5           3        NaN     NaN         A3        B3\n",
      "#Almost identifical to previous one: except the order of columns.\n"
     ]
    }
   ],
   "source": [
    "print('##customers##')\n",
    "print(customers)\n",
    "print(\"------------------------------------------------\")\n",
    "print('##shopping_history##')\n",
    "print(shopping_history)\n",
    "print(\"------------------------------------------------\")\n",
    "merged_outer= pd.merge(customers,shopping_history, how='outer')\n",
    "print(\"##Outer-Merge: 'customers' outer-merge on 'shopping_history'.##\")\n",
    "print (merged_outer)\n",
    "print(\"#Customer ID as 5 in 'shopping_history' doesn't have record in 'customer'.\")\n",
    "print(\"------------------------------------------------\")\n",
    "merged_left= pd.merge(customers,shopping_history, how='left')\n",
    "print(\"##Left-Merge: 'customers' left-merge on 'shopping_history'.##\")\n",
    "print (merged_left)\n",
    "print(\"#Only Customer ID in 'customer' and their matching data in 'shopping_history'.\")\n",
    "print(\"------------------------------------------------\")\n",
    "merged_right= pd.merge(shopping_history,customers, how='right')\n",
    "print(\"##Right-Merge: 'shopping_history' right-merge on 'customers'.##\")\n",
    "print (merged_right)\n",
    "print(\"#Almost identifical to previous one: except the order of columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Many-to-many merge:\n",
    "A more complicated relationship to manage using merge method is the many-to-many. Consider the example of customers and products. The customer DataFrame contains information about customers, while products has details about differnt grocery items. One customer can buy non or many products, and any product can be purchased by non or many customers. Pandas manage this relationship using merge method. Like SQL's JOIN clause, pandas.merge allows two DataFrames to be joined on one or more keys. The function provides a series of parameters (on, left_on, right_on, left_index, right_index) allowing you to specify the columns or indexes on which to join. In version 0.17.0. Pandas added the argument indicator. If True, a Categorical-type column called _merge will be added to the output object that takes on values. Here is a simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   d1 key\n",
      "0   0   a\n",
      "1   1   a\n",
      "2   2   b\n",
      "3   3   c\n",
      "4   4   a\n",
      "5   5   b\n",
      "6   6   c\n",
      "   d1 key\n",
      "0   0   d\n",
      "1   1   d\n",
      "2   2   b\n",
      "3   3   b\n",
      "4   4   b\n",
      "5   5   a\n",
      "    d1 key      Exists\n",
      "0    0   a   left_only\n",
      "1    1   a   left_only\n",
      "2    2   b        both\n",
      "3    3   c   left_only\n",
      "4    4   a   left_only\n",
      "5    5   b   left_only\n",
      "6    6   c   left_only\n",
      "7    0   d  right_only\n",
      "8    1   d  right_only\n",
      "9    3   b  right_only\n",
      "10   4   b  right_only\n",
      "11   5   a  right_only\n",
      "#left_only: this record only exist in left dataset\n",
      "#right_only: this record only exist in right dataset\n",
      "#both: this record exist in both datasets\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame({'key': ['a', 'a', 'b', 'c', 'a', 'b','c'], 'd1': range(7)})\n",
    "df2 = pd.DataFrame({'key': ['d', 'd', 'b', 'b', 'b', 'a'], 'd1': range(6)})\n",
    "print(df1)\n",
    "print(df2)\n",
    "merge= pd.merge(df1,df2, how='outer',indicator='Exists')\n",
    "print(merge)\n",
    "print(\"#left_only: this record only exist in left dataset\")\n",
    "print(\"#right_only: this record only exist in right dataset\")\n",
    "print(\"#both: this record exist in both datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   d1 key\n",
      "0   0   a\n",
      "1   1   a\n",
      "2   2   b\n",
      "3   3   c\n",
      "4   4   a\n",
      "5   5   b\n",
      "6   6   c\n",
      "   d1 key\n",
      "0   0   d\n",
      "1   1   d\n",
      "2   2   b\n",
      "3   3   b\n",
      "4   4   b\n",
      "5   5   a\n",
      "   d1 key_x key_y     Exists\n",
      "0   0     a     d       both\n",
      "1   1     a     d       both\n",
      "2   2     b     b       both\n",
      "3   3     c     b       both\n",
      "4   4     a     b       both\n",
      "5   5     b     a       both\n",
      "6   6     c   NaN  left_only\n"
     ]
    }
   ],
   "source": [
    "print (df1)\n",
    "print (df2)\n",
    "merge= pd.merge(df1,df2, how='outer',indicator='Exists', on='d1')\n",
    "print (merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In cases that there is a meaningful index in one of the columns, this index can replace the original DataFrame index. By default, set index returns a new DataFrame, so you will have to specify if you would like the changes to occur in place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Join:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### inner-join\n",
    "<img src=\"./inner-join.png\", alt='inner-join', width=\"200\">\n",
    "$$A \\cap B$$\n",
    "\n",
    "#### Left-Join (Left-Outer Join)\n",
    "<img src=\"./left-outer-join.png\", alt='Left-outer-join', width=\"200\">\n",
    "$$A \\cup B + A \\cap B - B = A$$\n",
    "\n",
    "#### left-outer-join to exclude B\n",
    "<img src=\"./left-outer-join-exclude B.png\", alt='left-outer-join-exclude B', width=\"200\">\n",
    "$$A \\cup B - B$$\n",
    "\n",
    "#### Full-Outer-Join = both A and B\n",
    "<img src=\"./full-outer-join.png\", alt='full-outer-join', width=\"200\">\n",
    "$$A \\cup B$$\n",
    "\n",
    "#### Full-outer-join to exclude conjuction of A and B\n",
    "<img src=\"./full-outer-join-exclude both A and B.png\", alt='full-outer-join-exclude both A and B.png', width=\"200\">\n",
    "$$A \\cup B - A \\cap B$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            First_Name Last_Name\n",
      "Customer_ID                     \n",
      "1                   A1        B1\n",
      "2                   A2        B2\n",
      "3                   A3        B3\n",
      "4                   A4        B4\n",
      "            Product_ID product\n",
      "Customer_ID                   \n",
      "1                  100     Oil\n",
      "1                  200   Sugar\n",
      "1                  300     Tea\n",
      "4                  400    Milk\n",
      "5                  500    Eggs\n"
     ]
    }
   ],
   "source": [
    "customers.set_index('Customer_ID', inplace=True)\n",
    "shopping_history.set_index('Customer_ID', inplace=True)\n",
    "print (customers)\n",
    "print (shopping_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DataFrame also has a convenient join method for merging on the index. This is used when you have objects with similar row labels, but different columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            First_Name Last_Name\n",
      "Customer_ID                     \n",
      "1                   A1        B1\n",
      "2                   A2        B2\n",
      "3                   A3        B3\n",
      "4                   A4        B4\n",
      "            Product_ID product\n",
      "Customer_ID                   \n",
      "1                  100     Oil\n",
      "1                  200   Sugar\n",
      "1                  300     Tea\n",
      "4                  400    Milk\n",
      "5                  500    Eggs\n",
      "            First_Name Last_Name Product_ID product\n",
      "Customer_ID                                        \n",
      "1                   A1        B1        100     Oil\n",
      "1                   A1        B1        200   Sugar\n",
      "1                   A1        B1        300     Tea\n",
      "2                   A2        B2        NaN     NaN\n",
      "3                   A3        B3        NaN     NaN\n",
      "4                   A4        B4        400    Milk\n",
      "5                  NaN       NaN        500    Eggs\n"
     ]
    }
   ],
   "source": [
    "joined= customers.join(shopping_history,how=\"outer\") #full-outer-join\n",
    "print (customers)\n",
    "print (shopping_history)\n",
    "print (joined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * Combining data with overlap: \n",
    "\n",
    "We use this method when we want to “patch” values in one object from values for matching indices in the other.  Note that this method only takes values from the right DataFrame if they are missing in the left DataFrame. Consider the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data 1\n",
      "     0   1    2\n",
      "0  1.0   3  NaN\n",
      "1  NaN  10  NaN\n",
      "2  NaN   5  3.0\n",
      "--------------\n",
      "Data 1\n",
      "      0    1    2\n",
      "0  10.0  NaN  4.0\n",
      "1   NaN  5.0  3.0\n",
      "2   2.0  4.0  NaN\n",
      "--------------\n",
      "Combine\n",
      "     0   1    2\n",
      "0  1.0   3  4.0\n",
      "1  NaN  10  3.0\n",
      "2  2.0   5  3.0\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data1= pd.DataFrame([[1,3,np.nan],[np.nan,10,np.nan],[np.nan,5,3]])\n",
    "data2= pd.DataFrame([[10,np.nan,4],[np.nan,5,3],[2,4,np.nan]])\n",
    "print(\"Data 1\")\n",
    "print(data1)\n",
    "print(\"--------------\")\n",
    "print(\"Data 1\")\n",
    "print(data2)\n",
    "print(\"--------------\")\n",
    "data= data1.combine_first(data2)\n",
    "print(\"Combine\")\n",
    "print(data)\n",
    "print(\"--------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic data Reshaping: \n",
    "\n",
    "### Hierarchical indexing : Stack and unstack \n",
    "\n",
    "Hierarchical indexing provides a more structure way of presenting tabular data. There are **two main methods** for pivoting data with Hierarchical indexing. \n",
    "\n",
    "* **stack**: this “rotates” or pivots from the columns in the data to the rows\n",
    "* **unstack**: this pivots from the rows into the columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`zip(*list)`: with function `*` which will **unpack** the list\n",
    "\n",
    "**Example**:  \n",
    "```Python\n",
    "In []: list(zip(*[[1,2],[3,4]]))\n",
    "Out[]: [(1, 3), (2, 4)]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple-Indexing\n",
    "```Python\n",
    "multi_index = pd.MultiIndex.from_tuples(tuples, names=['1st', '2nd'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack\n",
    "```Python\n",
    "pandas.DataFrame.stack()\n",
    "```\n",
    "It return a reshaped DataFrame or Series having a multi-level index with one or more **new inner-most levels** compared to the current DataFrame. The new inner-most levels are created by **pivoting** the columns of the current dataframe:\n",
    "\n",
    "* if the columns have **a single level**, the output is a **Series**;\n",
    "* if the columns have **multiple levels**, the new index level(s) is (are) taken from the prescribed level(s) and the output is a DataFrame.\n",
    "\n",
    "The new index levels are sorted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          A         B\n",
      "0  1.207376 -0.110377\n",
      "1 -1.661651  1.165869\n",
      "2 -0.500525 -1.265514\n",
      "3  1.229052 -0.583861\n",
      "4  0.545316  1.059960\n",
      "5 -1.025643 -1.239282\n",
      "6 -0.492065 -1.575757\n",
      "7 -0.837516  1.832702\n",
      "                     A         B\n",
      "first second                    \n",
      "L1_A  L2_1    1.207376 -0.110377\n",
      "      L2_2   -1.661651  1.165869\n",
      "L1_B  L2_1   -0.500525 -1.265514\n",
      "      L2_2    1.229052 -0.583861\n",
      "L1_C  L2_1    0.545316  1.059960\n",
      "      L2_2   -1.025643 -1.239282\n",
      "L1_D  L2_1   -0.492065 -1.575757\n",
      "      L2_2   -0.837516  1.832702\n",
      "first  second   \n",
      "L1_A   L2_1    A    1.207376\n",
      "               B   -0.110377\n",
      "       L2_2    A   -1.661651\n",
      "               B    1.165869\n",
      "L1_B   L2_1    A   -0.500525\n",
      "               B   -1.265514\n",
      "       L2_2    A    1.229052\n",
      "               B   -0.583861\n",
      "L1_C   L2_1    A    0.545316\n",
      "               B    1.059960\n",
      "       L2_2    A   -1.025643\n",
      "               B   -1.239282\n",
      "L1_D   L2_1    A   -0.492065\n",
      "               B   -1.575757\n",
      "       L2_2    A   -0.837516\n",
      "               B    1.832702\n",
      "dtype: float64\n",
      "#Note: A and B columns have been propagated to corresponding row\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "tuples = list(zip(*[['L1_A', 'L1_A', 'L1_B', 'L1_B','L1_C', 'L1_C', 'L1_D', 'L1_D'], \n",
    "                    ['L2_1', 'L2_2', 'L2_1','L2_2','L2_1', 'L2_2', 'L2_1','L2_2']]))\n",
    "multi_index = pd.MultiIndex.from_tuples(tuples, names=['first', 'second'])\n",
    "#data = pd.DataFrame(np.random.randn(8, 2), index=multi_index columns=['A', 'B'])\n",
    "data = pd.DataFrame(np.random.randn(8, 2), columns=['A', 'B'])\n",
    "print(data)\n",
    "data.index = multi_index\n",
    "print(data)\n",
    "result=data.stack()#pivoting the columns\n",
    "print(result)\n",
    "print('#Note: A and B columns have been propagated to corresponding row')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first  second   \n",
       "L1_A   L2_1    A    1.207376\n",
       "               B   -0.110377\n",
       "       L2_2    A   -1.661651\n",
       "               B    1.165869\n",
       "L1_B   L2_1    A   -0.500525\n",
       "               B   -1.265514\n",
       "       L2_2    A    1.229052\n",
       "               B   -0.583861\n",
       "L1_C   L2_1    A    0.545316\n",
       "               B    1.059960\n",
       "       L2_2    A   -1.025643\n",
       "               B   -1.239282\n",
       "L1_D   L2_1    A   -0.492065\n",
       "               B   -1.575757\n",
       "       L2_2    A   -0.837516\n",
       "               B    1.832702\n",
       "dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               A                   B          \n",
      "second      L2_1      L2_2      L2_1      L2_2\n",
      "first                                         \n",
      "L1_A    1.207376 -1.661651 -0.110377  1.165869\n",
      "L1_B   -0.500525  1.229052 -1.265514 -0.583861\n",
      "L1_C    0.545316 -1.025643  1.059960 -1.239282\n",
      "L1_D   -0.492065 -0.837516 -1.575757  1.832702\n"
     ]
    }
   ],
   "source": [
    "print(data.unstack())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            First_Name Last_Name\n",
      "Customer_ID                     \n",
      "1                   A1        B1\n",
      "2                   A2        B2\n",
      "3                   A3        B3\n",
      "4                   A4        B4\n",
      "            Product_ID product\n",
      "Customer_ID                   \n",
      "1                  100     Oil\n",
      "1                  200   Sugar\n",
      "1                  300     Tea\n",
      "4                  400    Milk\n",
      "5                  500    Eggs\n",
      "            First_Name Last_Name Product_ID product\n",
      "Customer_ID                                        \n",
      "1                   A1        B1        100     Oil\n",
      "1                   A1        B1        200   Sugar\n",
      "1                   A1        B1        300     Tea\n",
      "2                   A2        B2        NaN     NaN\n",
      "3                   A3        B3        NaN     NaN\n",
      "4                   A4        B4        400    Milk\n",
      "5                  NaN       NaN        500    Eggs\n"
     ]
    }
   ],
   "source": [
    "joined= customers.join(shopping_history, how= 'outer')#customers full-outer-join on history\n",
    "print (customers)\n",
    "print (shopping_history)\n",
    "print (joined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Try to implement the same code using pivot (http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.pivot.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplication: \n",
    "\n",
    "The DataFrame method 'duplicated' returns a Boolean Series indicating whether each row is a duplicate or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first  second\n",
       "L1_A   L2_1      False\n",
       "       L2_2      False\n",
       "L1_B   L2_1      False\n",
       "       L2_2      False\n",
       "L1_C   L2_1      False\n",
       "       L2_2      False\n",
       "L1_D   L2_1      False\n",
       "       L2_2      False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relatedly, `drop_duplicates()` returns a DataFrame where the duplicated array is without duplicated rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       k1  k2\n",
      "0    Milk   1\n",
      "1    Milk   1\n",
      "2    Milk   2\n",
      "3  Cheese   3\n",
      "4  Cheese   3\n",
      "5  Cheese   4\n",
      "6  Cheese   4\n",
      "###After deduplication\n",
      "       k1  k2\n",
      "0    Milk   1\n",
      "2    Milk   2\n",
      "3  Cheese   3\n",
      "5  Cheese   4\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame({'k1': ['Milk'] * 3 + ['Cheese'] * 4,  'k2': [1, 1, 2, 3, 3, 4, 4]})\n",
    "print (data)\n",
    "data.duplicated()\n",
    "cleandata= data.drop_duplicates()\n",
    "print(\"###After deduplication\")\n",
    "print(cleandata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may have noticed, applying `drop_duplicates()` on the whole DataFrame considers all other columns together. We can alternatively **specify at which column** we want to capture the duplication. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       k1  k2\n",
      "0    Milk   1\n",
      "3  Cheese   3\n",
      "       k1  k2\n",
      "0    Milk   1\n",
      "2    Milk   2\n",
      "3  Cheese   3\n",
      "5  Cheese   4\n"
     ]
    }
   ],
   "source": [
    "v1= data.drop_duplicates(['k1'])\n",
    "print (v1)\n",
    "v2=  data.drop_duplicates(['k2'])\n",
    "print (v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming axis indexes: \n",
    "\n",
    "Pandas enable modifying the current attribute name using map or renaming methods. Example is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          day1  day2  day3  day4\n",
      "nsw          0     1     2     3\n",
      "vic          4     5     6     7\n",
      "tasmania     8     9    10    11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAY1</th>\n",
       "      <th>DAY2</th>\n",
       "      <th>DAY3</th>\n",
       "      <th>DAY4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Nsw</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vic</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tasmania</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DAY1  DAY2  DAY3  DAY4\n",
       "Nsw          0     1     2     3\n",
       "Vic          4     5     6     7\n",
       "Tasmania     8     9    10    11"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf= pd.DataFrame(np.arange(12).reshape((3, 4)), \n",
    "                  index=['nsw', 'vic', 'tasmania'],\n",
    "                  columns=['day1', 'day2', 'day3', 'day4'])\n",
    "print (idf)\n",
    "#idf.index.map(str.title)\n",
    "idf.rename(index=str.title, columns=str.upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day1</th>\n",
       "      <th>day2</th>\n",
       "      <th>day3</th>\n",
       "      <th>day4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nsw</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vic</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tasmania</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          day1  day2  day3  day4\n",
       "nsw          0     1     2     3\n",
       "vic          4     5     6     7\n",
       "tasmania     8     9    10    11"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note rename keeps the original value of the data unchanged. To change the original DataFrame, you need to do that `inplace`. You can also  rename a subset of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAY1</th>\n",
       "      <th>DAY2</th>\n",
       "      <th>DAY3</th>\n",
       "      <th>DAY4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NSW</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VIC</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TASMANIA</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DAY1  DAY2  DAY3  DAY4\n",
       "NSW          0     1     2     3\n",
       "VIC          4     5     6     7\n",
       "TASMANIA     8     9    10    11"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#idf.index=idf.index.map(str.upper)\n",
    "#OR\n",
    "idf.rename(index=str.upper, columns=str.upper, inplace=True)\n",
    "idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More details and examples can be found in http://pandas.pydata.org/pandas-docs/stable/merging.html and \"Python for Data Analysis\" book pages 177-193.\n",
    "https://nikolaygrozev.wordpress.com/2015/07/01/reshaping-in-pandas-pivot-pivot-table-stack-and-unstack-explained-with-pictures/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "name": "Chapter 6_Merging and Reshaping Data.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
