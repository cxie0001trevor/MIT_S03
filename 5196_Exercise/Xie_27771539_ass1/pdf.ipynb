{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIT5196 Task 2 in Assessment 1\n",
    "#### Student Name: Chuangfu Xie\n",
    "#### Student ID: 27771539\n",
    "\n",
    "Date: 08/04/2018\n",
    "\n",
    "Version: 2.0\n",
    "\n",
    "Environment: Python 3.6.4 and Jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print (sys.version_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pdfminer\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2. Parse PDF File\n",
    "### 2.1 Parse .PDF to .txt\n",
    "In this task, we use `pdf2txt.py` to convert PDF file to a text file. In case of the `pdf2txt.py` can run on your machine, please type the following scripts to install `pdfminer.six` [Check more about pdfminer.six](https://anaconda.org/conda-forge/pdfminer.six):\n",
    "```shell\n",
    "    conda install -c conda-forge pdfminer.six\n",
    "```\n",
    "Then run the following command in the terminal:\n",
    "```shell\n",
    "    pdf2txt.py -o health.txt health.pdf\n",
    "```\n",
    "\n",
    "**Note**: The scripts shown above are supposed to be run in macOS. As my python version is 3.6.4, we need pdfminer.six as pdfminer is not compatible with python 3.\n",
    "***\n",
    "Then, we make use of `repr()` to inspect the content of the txt file since `\\n` is not visiable in default print out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pdfTxtFile = './health.txt'\n",
    "pdf_txt = open(pdfTxtFile, 'r')\n",
    "for line in pdf_txt:\n",
    "    print (repr(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Collect all country name\n",
    "First, we need collect all the country names from the txt file.  \n",
    "Based on the previous output, we can find that country names in the first pages begins right behind the `'and areas\\n'`:\n",
    "```python\n",
    "    'Countries \\n'\n",
    "    'and areas\\n'  <-- Starts collecting\n",
    "    '63\\n'\n",
    "    'Afghanistan\\n'\n",
    "    '91\\n'\n",
    "    'Albania\\n'\n",
    "    '93\\n'\n",
    "```\n",
    "and finishes right before `'\\n'`:\n",
    "```python\n",
    "    'Ethiopia\\n'\n",
    "    '39\\n'\n",
    "    '94\\n'\n",
    "    'Fiji\\n'\n",
    "    '\\n'    <-- Ends collecting\n",
    "```\n",
    "We can use **Regular Expression** pattern to ease the work:\n",
    "* To match strings only containing whitespaces character\n",
    "```python\n",
    "   r'^\\s*$'\n",
    "```\n",
    "* To deal with some anomalies, such as: 'Democratic Republic of the Congo 42\\n'\n",
    "```python\n",
    "    r'^([A-Z].+?)\\d*\\n'\n",
    "```\n",
    "**Note**: As i use group in the regular expression, the number `'42'` need to be inserted back to the data when we collect the cell values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pdfTxtFile = './health.txt'\n",
    "pdf_txt = open(pdfTxtFile, 'r')\n",
    "reg1 = re.compile(r'^\\s*$')\n",
    "reg2 = re.compile(r'^([A-Z].+?)\\d*\\n')\n",
    "isName = False\n",
    "countryNames = {1:[],2:[],3:[],4:[]}\n",
    "record_per_page = []\n",
    "page_num = 1\n",
    "for line in pdf_txt:\n",
    "    if isName and reg1.match(line)== None:\n",
    "        if reg2.match(line):\n",
    "            if not countryNames[page_num]:\n",
    "                countryNames[page_num]=[]\n",
    "            countryNames[page_num].append(reg2.match(line).group(1).strip())\n",
    "    if line.startswith('and areas'):\n",
    "        isName = True\n",
    "    elif isName and reg1.match(line)!= None:\n",
    "        isName = False\n",
    "        page_num+=1\n",
    "countryNames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As result print above, all the country names have been successfully extracted from the txt file. By using dictionary we can easily found how many records in each page by `len()`. However, there are two country names seperated into two strings that we need to deal with:  \n",
    "At page 1:\n",
    "```\n",
    "    \"Democratic People's Republic of\", \n",
    "    'Korea'\n",
    "```\n",
    "At page 3:\n",
    "```\n",
    "    'The former Yugoslav Republic of', \n",
    "    'Macedonia'\n",
    "```\n",
    "By `index()`, we can find out the index of both country names.\n",
    "```python\n",
    "    >>> countryNames[1].index('Democratic People\\'s Republic of')\n",
    "    ... 48\n",
    "    >>> countryNames[3].index('The former Yugoslav Republic of')\n",
    "    ... 52\n",
    "```\n",
    "We need to merge their name back to what they truly are. After that, we can get the exactly number of country in each page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countryNames[1][48] = 'Democratic People\\'s Republic of Korea'\n",
    "countryNames[1].remove(\"Korea\")\n",
    "countryNames[3][52] = 'The former Yugoslav Republic of Macedonia'\n",
    "countryNames[3].remove(\"Macedonia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can calculate how many records in each page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_per_page = []\n",
    "for i in range(1,5,1):\n",
    "    rec_per_page.append(len(countryNames[i]))\n",
    "rec_per_page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Collect data from all columns\n",
    "As we don't need data from 'SUMMARY' part, We can collect all cell values by the following patterns :\n",
    "```python\n",
    "    ...\n",
    "    '2011–2016*\\n' <-- Start collecting data\n",
    "    '\\n'\n",
    "    '100\\n'\n",
    "    ...\n",
    "    '98\\n'\n",
    "    '\\n'           <-- Ending Collecting data of a column\n",
    "    'SUMMARY\\n'    <-- Stop collecting data\n",
    "    ...\n",
    "```\n",
    "and:\n",
    "```python\n",
    "    '61 x\\n' #The only part we need is the numeric part\n",
    "```\n",
    "Thus, we use regular expressions to collect all data:\n",
    "```python\n",
    "    r'^(\\d{1,3}|–)\\s?[x]?\\n$'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfTxtFile = './health.txt'\n",
    "pdf_txt = open(pdfTxtFile, 'r')\n",
    "reg3 = re.compile(r'^(\\d{1,3}|–)\\s?[x]?\\n$')\n",
    "all_data = []\n",
    "each_column = []\n",
    "isData = False\n",
    "for line in pdf_txt:\n",
    "    if isData and reg3.match(line)!= None:\n",
    "        each_column.append(reg3.match(line).group(1))\n",
    "    if line.startswith('2011–2016'):\n",
    "        isData = True\n",
    "    elif line == '\\n':\n",
    "        if each_column:\n",
    "            all_data.append(each_column)\n",
    "        each_column = []\n",
    "    elif isData and line.startswith('SUMMARY'):\n",
    "        isData = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recalling that we need to inserted back the value `'42'` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[0].insert(countryNames[1].index(\"Democratic Republic of the Congo\"),'42')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about the number of column? Since we already have the number of records on each page: `[62, 63, 63, 14]`, the problem becomes simple: we only need to calculate how many columns are in length of 62."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_col = 0\n",
    "for index_col in range(len(all_data)): \n",
    "    if len(all_data[index_col]) == 62:\n",
    "        num_col +=1\n",
    "print(num_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can distribute all data to their corresponding columns in each pages.  \n",
    "Recalling there are only 14 records on the very last pages and the conversion are just like a mess. Thus, to simplify the process, only those columns which has exactly 14 records will be assigned to `page4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "page1 = all_data[:22]\n",
    "page2 = all_data[22:44]\n",
    "page3 = all_data[44:66]\n",
    "page4 = []\n",
    "for i in range(len(all_data)):\n",
    "    if len(all_data[i]) == 14:\n",
    "        page4.append(all_data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Export data in CSV\n",
    "### 3.1 Create DataFrame\n",
    "Now we have all data we need from the txt file. As we know that there are 202 row with 22 columns, let's create dataframe object to get ready for data fill-in: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.zeros((202,22)), columns = ['Country name']+list(range(21)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_Names = []\n",
    "for i in countryNames.keys():\n",
    "    all_Names += countryNames[i]\n",
    "df['Country name'] = all_Names\n",
    "for i in range(num_col):\n",
    "    df[i] = page1[i] + page2[i] + page3[i] + page4[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, if a cell value equals to `'–'`, then it will be replaced as an empty string `''`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.apply(lambda x: x.replace('–', ''), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Export CSV\n",
    "Export the dataframe to csv without index numbering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./pdf.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Summary\n",
    "During PDF parsing, I found that the most difficult thing is the inspection, that is, to find the pattern of data. It is very time-consuming as I have to manually check where the column data starts and where it ends. Though using regular expression have save some time in extracting particular data, I still need to re-check the matching result to ensure every records has been correctly collected."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
