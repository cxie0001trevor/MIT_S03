{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1B Hands on data - wrangling data with Python & pandas\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In two parts:\n",
    "* reproducing the DataWrangler process (using the same 'Air crashes' data) and \n",
    "* bad, bad data investigations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Before you start, a most important thing to do, check your python version**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print (sys.version_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # not the bamboo eating bear... 'Panel Data' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 \n",
    "## Step 1 Read data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv('AirCrashes.csv') # df is a dataframe, confirm with: type(df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many lines of data?\n",
    "#### How many did you get with DataWrangler?\n",
    "\n",
    "Have a look a the first few rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's not quite right.. the first line has been stolen for the title/header\n",
    "#### Does read_csv ignore empty lines? \n",
    "e.g. line 18 should be blank\n",
    "\n",
    "skip_blank_lines = True (the default) see:\n",
    "\n",
    "http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\n",
    "\n",
    "Try again, force our own headers upon the data using default column names from DataWrangler (split/extract etc.) \n",
    "\n",
    "This pushes the first incident down into the data where it belongs (but adds a NaN, below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('AirCrashes.csv', names = ['split', 'split1']) \n",
    "# column names (split, split1) replicate DataWrangler column names\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 Extract index(s)\n",
    "\n",
    "### Extract flight information\n",
    "The flight information is between \"Incident\" and \"involving\" in the \"split\" cell.\n",
    "Now, extract flights based on one of the suggestions from DataWrangler, i.e., \"(Incident (.*) involving)\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treat the 'split' column as a str, then \n",
    "# use the extract method on the str\n",
    "df['split'].str.extract(\"Incident (.*) involving\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That seems to have worked...\n",
    "\n",
    "We got 'American Airlines Flight 11' and 'United Airlines Flight 175' etc but lost all the other data and gained a bunch of NaNs\n",
    "\n",
    "#### What is this 'str.extract' code anyway? (add a comment to decode or explain it)\n",
    "\n",
    "extract(\"Incident (.*) involving\")\n",
    "\n",
    "### But we want planes in a new column, we can create one called 'extract' like this:\n",
    "\n",
    "df['extract'] = df['split'].str.extract(\"Incident (.*) involving\")\n",
    "\n",
    "But this would be the last column, we want it in the second (location is not critical but it can be done so why not). \n",
    "\n",
    "Now, use the DataFrame's insert function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there's the flight information in it's own column, plus a whole lot of NaNs\n",
    "\n",
    "We could replace all the NaN with spaces or similar but they can wait\n",
    "\n",
    "Now we want the aircraft in it's own column, similar to above, \n",
    "based on the suggestion from DataWrangler, note spaces in \"\\ a (.*)\\ in \"\n",
    "\n",
    "#### but is this optimal?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and repeat to get the aircraft type that appears between \"a\" and \"in\"\n",
    "\n",
    "# and df.head(20) to confirm\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the empty lines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(how='all') \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3  'Fill down'\n",
    "\n",
    "We want to 'fill down' the indexes  (e.g. lines 1 to 15 should be associated with line 0)\n",
    "\n",
    "There are several options\n",
    "* na.locf() method from zoo package. \n",
    "* ddply() from plyr\n",
    "* bfill()\n",
    "* fillna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# magic, take the previous value (not NaN) and fill down\n",
    "df =\n",
    "# http://pandas.pydata.org/pandas-docs/stable/missing_data.html#filling-missing-values-fillna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 Remove the index row\n",
    "\n",
    "We need to delete all the 'incident' rows, they have served their purpose and are now redundant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use str.contain function to get the row index.\n",
    "# keep everything that doesn't have \"Incident\" in it \n",
    "df = \n",
    "# do we need to worry about a plane called \"Incident\" or \"Incident weather\" etc???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and check with e.g. df.shape \n",
    "print df.shape\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now to 'unfold', there are several options\n",
    "\n",
    "* melt()\n",
    "* stack, unstack?\n",
    "* pivot_table()\n",
    "* pivot()\n",
    "\n",
    "http://pandas.pydata.org/pandas-docs/stable/reshaping.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.pivot('extract', 'split', 'split1') \n",
    "# the parameters above are (left to right) index, columns, values \n",
    "# You can also write it like this:\n",
    "#data = df.pivot(index = 'extract', columns = 'split', values = 'split1') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.head() # 58 records, good, but lost plane type, bad\n",
    "# where's 'extract1' - can we have multiple indexes or have to put that data back in?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem:\n",
    "\n",
    "we have two columns we want to pivot on, 'extract' & 'extract1' (AKA flight & plane) but\n",
    "\n",
    "pivot() can't have multiple indexes...\n",
    "\n",
    "e.g. df.pivot(index = ['extract','extract1'], 'split', 'split1') # error\n",
    "\n",
    "pivot_table() can but insists on doing some accounting or aggreagating too, like sum or avg, which we don't need\n",
    "\n",
    "e.g. pd.pivot_table(df, values='split1', index = ['extract','extract1'], columns='split') # error, no function \n",
    "\n",
    "### Solutions? \n",
    "\n",
    "use pivot() then force the other column back into the data?? \n",
    "\n",
    "or trick pivot_table() into doing some pointless accounting (that adds up to nothing)??\n",
    "\n",
    "try something else... stack, unstack, group, dplyr?\n",
    "\n",
    "DIY code??\n",
    "\n",
    "\n",
    "\n",
    "![](http://www.desktopimages.org/pictures/2014/0212/1/orig_150933.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# solution: make the function a copy, x = x\n",
    "# data = pd.pivot_table(df, index=[\"extract\",\"extract1\"], columns = 'split', values = 'split1', aggfunc = lambda x: x)   \n",
    "# or \n",
    "data = pd.pivot_table(df, index=[\"extract\",\"extract1\"], columns = 'split', values = 'split1', aggfunc = 'max') \n",
    "# ha, cop that\n",
    "# http://stackoverflow.com/questions/19279229/pandas-pivot-table-with-non-numeric-values-dataerror-no-numeric-types-to-ag\n",
    "\n",
    "data # not using df anymore, keep it as backup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That's most of the wrangling as was done with DataWrangler, there are a few more optional steps:\n",
    "* want the manufacturer e.g. Beoing?\n",
    "* remove 'extract' & 'extract1'?\n",
    "* rename columns ('split') \n",
    "* extract year into new column \n",
    "* export e.g. df.to_csv(file_name, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 \n",
    "\n",
    "## Wait there's more:\n",
    "\n",
    "Bad, bad data\n",
    "\n",
    "This data has been deliberately damaged (sorry)\n",
    "\n",
    "Some are obvious, some are subtle (some were already there... e.g. look for 'Â')\n",
    "\n",
    "### See if you can find them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with a summary table\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### describe() shows:\n",
    "\n",
    "* count - we can see that there are 58 records across the board, no surprise (what would it mean if there were non 58s?)\n",
    "* unique - looks like all the 'Casualties' are identical (unique = 1, i.e. all 'Extremely High'), maybe this column is redundant?\n",
    "* top - interesting, there were two major disasters in the exact same place? Check dates?\n",
    "* freq - also interesting, 3 times there were 156 passengers on flights... superstitious? Or is it bad data?\n",
    "\n",
    "So some clues here, dig deeper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can also describe individual columns:\n",
    "data['Crew'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nothing new here, the most common number crew size is 14 (7 times)\n",
    "# what's the biggest crew?\n",
    "data['Crew'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Why 9 (or even '9')?\n",
    "\n",
    "How can this max be less than 14?\n",
    "\n",
    "Are these even numbers?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Crew'].mean() # expecting ~15, they were all big planes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is weird\n",
    "\n",
    "If they are numbers it should be higher\n",
    "\n",
    "If they are not numbers, what does mean 'mean'? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['Crew'] == 14] # look at all the crew = 14 planes, should be 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are none... try this:\n",
    "data[data['Crew'] == '14'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so there's a clue, 14 vs '14' \n",
    "# what are these data types anyway?\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All data are of type object... \n",
    "### Overruled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.convert_objects(convert_numeric = True) \n",
    "# this is a bit brutal, can you convert when data is loaded?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so now we have some numbers (int & float)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Better, more information, describe() now shows:\n",
    "* count - as above, all 58\n",
    "* mean - crew ~15, seems OK, but mean lat & long doesn't mean much... or does it?\n",
    "* std - Standard Deviation\n",
    "* min - now we see some problems, zero crew? Was this a way to code a hijacking, or is it missing, or should it be 10, 20, 30?\n",
    "* 25, 50 & 75% are quartiles...\n",
    "* max - crew 181, no way! 1692 dead, no plane is that big... or could this be Lockerbie, i.e. plane hit town\n",
    "\n",
    "Let's investigate the crew data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['Crew'] > 20] # try also e.g. < 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So Boeing 747s have large crews...\n",
    "#### 33 crew is that possible? Or is that two flights?\n",
    "\n",
    "#### 181 crew? Same value as for 'Total dead', can you derive crew from dead minus passengers?\n",
    "(or does 'Some survivors' corrupt the maths?)\n",
    "\n",
    "\n",
    "# Another way to explore... plot that data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "# notebook majik to display plots in the notebook\n",
    "\n",
    "data[['Crew','Passengers']].plot(x= 'Crew',y= 'Passengers',kind= 'scatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### And there's the extreme outlier\n",
    "#### Are there any others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so how to put a number to an outlier?\n",
    "data['Crew'].max() # works, now that they are numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['Crew']==data['Crew'].max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting non-numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Phase'].value_counts().plot(kind='bar')\n",
    "# you can guess some of these codes\n",
    "# ENR = en route?\n",
    "# APR = Aproach\n",
    "# Takeoff, Landing\n",
    "# ICL?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not much point in plotting Casualties... so what the hey\n",
    "data['Casualties'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To do: find any other data problems (there are about 10)\n",
    "\n",
    "<br>\n",
    "\n",
    "![](http://media1.popsugar-assets.com/files/thumbor/yjoSwHRBZ4MpTO3TN6lvI_gsKMI/fit-in/2048xorig/filters:format_auto-!!-:strip_icc-!!-/2016/03/02/901/n/1922283/01f64bd801c06153_game4/i/When-Everyone-Trying-Talk-You-Youre-Too-Hungry-Care.gif)\n",
    "\n",
    "#### Post your suspected bad data cases in Moodle discussion forums, how you found it, and suggested fixes\n",
    "(one or two each, share the load)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# go crazy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Can data be 'typed' as it is read in? \n",
    "(yes see 'dtype')\n",
    "http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\n",
    "#### What happens if this process encounters bad data?\n",
    "\n",
    "#### So why is 'Crew' max '9' above?\n",
    "\n",
    "#### When a plane hits another plane is that one record or two?\n",
    "\n",
    "#### Can DataWrangler do this sort of wrangling? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "name": "DataWranglering with Python.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
