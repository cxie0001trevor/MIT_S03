{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIT5196 Task 1 in Assessment 2\n",
    "#### Student Name: Chuangfu Xie\n",
    "#### Student ID: 27771539\n",
    "\n",
    "Date: 28/04/2018\n",
    "\n",
    "Version: 1.0\n",
    "\n",
    "Environment: Pandas 0.22.0, Python 3.6.4 and Jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print (sys.version_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "print(\"Your Pandas version: \" + pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Auditing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, read CSV file from current directory by `read_csv()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./dataset1_with_error.csv\")\n",
    "# Take a peek at data \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since <font color='blue'>**Id**</font> are identifiers of these data, let's check whether it contains duplicated records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df['Id'].duplicated())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No duplicated record is great. Then, let's have a overview of this dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check overall info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Check on Date data: `OpenDate` and `CloseDate`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we intend to find out **whether any data contains anomalies** in <font color='blue'>**OpenDate**</font> and <font color='blue'>**CloseDate**</font>. It can be syntactical anomalies, semantic anomalies, or coverage anomalies. From output above, we can find that value stored in these two colums are both in `object` type. However, if we want to check whether the date are valid, we need to convert these data from `object` type to `datetime` type.  \n",
    "First. let's start from its **format**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def check_date(data, col):\n",
    "    '''\n",
    "    With common sense, this function applies constraints on each data, \n",
    "    then return a list of indices of all errors.\n",
    "    > Arguments:\n",
    "    data: DataFrame. Pandas.DataFrame object\n",
    "    col: str. Target column, 'OpenDate', 'CloseDate'\n",
    "    > Return:\n",
    "    error_list: a list of indices of all errors\n",
    "    '''\n",
    "    #initialise a set for storing indices(avoid duplicate)\n",
    "    errors = []\n",
    "    # Check every record\n",
    "    for i,each in enumerate(data[col]):\n",
    "        try:\n",
    "            pd.to_datetime(each)\n",
    "        except ValueError:\n",
    "            errors.append(i)\n",
    "    return errors\n",
    "\n",
    "error_list = check_date(df, 'OpenDate')\n",
    "# Have a look at those error\n",
    "df.iloc[error_list]['OpenDate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, these **10 records** fail to convert into `datetime` type, which means these data format are <font color='red'>**inconsistent**</font> with normal date value format. We should invert the position of day and month.  \n",
    "With `check_date` function, now we have anomalies index. Let's create another function as `rectify_date` to rectify these errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rectify_date(data, col):\n",
    "    '''\n",
    "    This function is to rectify date format error in place.\n",
    "    > Arguments:\n",
    "    data: DataFrame. Pandas.DataFrame object\n",
    "    col: str. Target column, 'OpenDate', 'CloseDate'\n",
    "    '''\n",
    "    re_pattern = r'^(?P<year>\\d{4})(?P<month>\\d{2})(?P<day>\\d{2})(?P<time>T\\d{6})'\n",
    "    error_list = check_date(data, col)\n",
    "    for i in error_list:\n",
    "        datedict = re.match(re_pattern, data[col][i]).groupdict()\n",
    "        # construct replaced date\n",
    "        rep_d = datedict['year']+datedict['day']+datedict['month']+datedict['time']\n",
    "        # rectify format in place.\n",
    "        data.at[i,col] = rep_d\n",
    "\n",
    "# Rectify data in 'OpenDate' and 'CloseDate'\n",
    "rectify_date(df, 'OpenDate')\n",
    "# Double-check on those errors\n",
    "df.iloc[error_list]['OpenDate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Apply same process on 'CloseDate'\n",
    "rectify_date(df,'CloseDate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having all date in correct format, now we can check whether data spread in <font color='blue'>**OpenDate**</font> and <font color='blue'>**CloseDate**</font> have **violate the integrity constraint**: the date value on <font color='blue'>**OpenDate**</font> should be **preceding to** that on <font color='blue'>**CloseDate**</font>.    \n",
    "To find out if there any, we first need to convert <font color='blue'>**OpenDate**</font> and <font color='blue'>**CloseDate**</font> into `datatime` type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['OpenDate'] = pd.to_datetime(df['OpenDate'])\n",
    "df['CloseDate'] = pd.to_datetime(df['CloseDate'])\n",
    "# Any violation?\n",
    "df[df['OpenDate']>df['CloseDate']].loc[:,['OpenDate','CloseDate']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have found **8 violations**. It seems like data in <font color='blue'>**OpenDate**</font> have been carelessly put into <font color='blue'>**CloseDate**</font> column. Let's change it back:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_d = df[df['OpenDate']>df['CloseDate']]['OpenDate']\n",
    "close_d = df[df['OpenDate']>df['CloseDate']]['CloseDate']\n",
    "error_list = df[df['OpenDate']>df['CloseDate']].index.tolist()\n",
    "for i,o,c in zip(error_list, open_d, close_d):\n",
    "    df.at[i,\"OpenDate\"]=c\n",
    "    df.at[i,\"CloseDate\"]=o\n",
    "# Double-check\n",
    "sum(df['OpenDate']>df['CloseDate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Checking on numeric data: `Salary per annum`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aforementioned process have shown how to rectify anomalies occour in date value, now we turn to numeric data: <font color='blue'>**Salary per annum**</font>.  \n",
    "Before we closely examine these data, we know data in column <font color='blue'>**Salary per annum**</font> are stored in `object` type. let's define a function to check whether data are in numberic format by conversion function `int()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_numeric(data, col):\n",
    "    errors=[]\n",
    "    for i,d in enumerate(data[col]):\n",
    "        try:\n",
    "            int(d)\n",
    "        except ValueError:\n",
    "            errors.append(i)\n",
    "    return errors\n",
    "\n",
    "alist = check_numeric(df, 'Salary per annum')\n",
    "df.iloc[alist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can easily find there are 3 different format in column <font color='blue'>**Salary per annum**</font>:\n",
    "\n",
    "```Python\n",
    "'24996'\t                <-- numeric\n",
    "'22K'                      <-- 'K' abbrevated for 1000\n",
    "'24646.8 - 27241.2'        <-- givn a range\n",
    "```\n",
    "These irregularities need to be uniformed. Especially, as to those range data, we use the mean of that range as the substitution data.  \n",
    "Here, we assume that after cleansing we only need interger value in salary. All data after processing by function `extract_salary()` would be converted to integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_salary(data, col):\n",
    "    range_pattern = r'(\\d+.\\d+) - (\\d+.\\d+)'\n",
    "    k_pattern = r'(\\d+)K'\n",
    "    errors = check_numeric(data,col)\n",
    "    for i,s in zip(errors, data.iloc[errors][col]):\n",
    "        if 'K' in s:\n",
    "            rep_n = 1000*int(re.match(k_pattern, s).group(1))\n",
    "            data.at[i,col] = rep_n\n",
    "        else:\n",
    "            rep_n = 0.5*(float(re.match(range_pattern, s).group(1)) + float(re.match(range_pattern, s).group(2)))\n",
    "            data.at[i,col] = int(round(rep_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_salary(df, 'Salary per annum')\n",
    "# Convert 'Salary per annum' to numeric type\n",
    "df['Salary per annum'] = pd.to_numeric(df['Salary per annum'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Checking on others columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously we have done our anormalies detection in column <font color='blue'>**OpenDate**</font>, <font color='blue'>**CloseDate**</font> and <font color='blue'>**Salary per annum**</font>. Now let's have a look at other columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ContractType.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column <font color='blue'>**ContractType**</font> only have 3 possible value: `not available`, `full_time`, `part_time`. \n",
    "However, the underscore \"\\_\" seem to be some typing error, we need to replace it with dash \"-\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rectify_contractType(data):\n",
    "    for i,t in enumerate(data['ContractType']):\n",
    "        if '_' in t:\n",
    "            rep = t.replace('_','-')\n",
    "            data.at[i,'ContractType'] = rep\n",
    "rectify_contractType(df)\n",
    "df.ContractType.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better.  \n",
    "Then, let's look at column <font color='blue'>**ContractTime**</font>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ContractTime.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing special. How about data in column <font color='blue'>**Category**</font>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.Category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about column <font color='blue'>**Title**</font>, <font color='blue'>**Location**</font>, <font color='blue'>**Company**</font> and <font color='blue'>**SourceName**</font>?  \n",
    "Data in these corresponding column are naturally diverse with seldom similarity, we just keep what they are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Export output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the dataframe to `CSV` without indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./dataset1_solution.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the instructions, I have find data problems included:\n",
    "1. Lexical errors: 'full_time' instead of 'full-time' in  <font color='blue'>**ContractType**</font>.  \n",
    "2. Irregularities: '24996','22K','24646.8 - 27241.2' in <font color='blue'>**Salary per annum**</font>.\n",
    "3. Violation of the Integrity constraint: <font color='blue'>**CloseDate**</font> preceding to <font color='blue'>**OpenDate**</font>.\n",
    "4. Inconsistency: '20180428T150000' against '20182804T150000' in <font color='blue'>**OpenDate**</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
